<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Fast Robots - Ronin Sharma's Wiki Site</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg bg-secondary text-uppercase fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand" href="#page-top">ECE 5960: Fast Robots</a>
                <button class="navbar-toggler text-uppercase font-weight-bold bg-primary text-white rounded" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto">
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded" href="#about">About</a></li>
                        <li class="nav-item mx-0 mx-lg-1"><a class="nav-link py-3 px-0 px-lg-3 rounded" href="#labs">Labs</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <header class="masthead bg-primary text-white text-center">
            <div class="container d-flex align-items-center flex-column">
                <!-- Masthead Avatar Image-->
                <img class="masthead-avatar mb-5 rounded" src="assets/img/Ronin3.jpg" alt="..." />
                <!-- Masthead Heading-->
                <h1 class="masthead-heading text-uppercase mb-0">Ronin Sharma</h1>
                <!-- Icon Divider-->
                <div class="divider-custom divider-light">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Masthead Subheading-->
                <p class="masthead-subheading font-weight-light mb-0">Computer Engineer - Software Engineer - Data Scientist</p>
            </div>
        </header>

        <!-- Lab Section-->
        <section class="page-section portfolio" id="labs">
            <div class="container">
                <!-- Portfolio Section Heading-->
                <h2 class="page-section-heading text-center text-uppercase text-secondary mb-0">Labs</h2>
                <!-- Icon Divider-->
                <div class="divider-custom">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- Portfolio Grid Items-->
                <div class="row justify-content-center">
                    <!-- Portfolio Item 1-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal1">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab1/Artemis.jpg" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 1</div>
                    </div>
                    <!-- Portfolio Item 2-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal2">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab2/USB_Bluetooth.png" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 2</div>
                    </div>
                    <!-- Portfolio Item 3-->
                    <div class="col-md-6 col-lg-4 mb-5">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal3">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab3/TOF_Sensor.jpg" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 3</div>
                    </div>
                    <!-- Portfolio Item 4-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal4">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="width:300px;" src="assets/img/Lab4/Car_Top.png" alt="..." />
                        </div>
                        <div class="lab-text text-center my-4">Lab 4</div>
                    </div>
                    <!-- Portfolio Item 5-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-md-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal5">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="width:300px;" src="assets/img/Lab5/Robot2.png" alt="..." />
                        </div>
                        <div class="lab-text text-center my-4">Lab 5</div>
                    </div>
                    <!-- Portfolio Item 6-->
                    <div class="col-md-6 col-lg-4">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal6">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:400px;" src="assets/img/Lab6/Robot.jpeg" alt="..." />
                        </div>
                        <div class="lab-text text-center my-4">Lab 6</div>
                    </div>
                    <!-- Portfolio Item 7-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal7">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab7/Lab7.png" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 7</div>
                    </div>
                    <!-- Portfolio Item 8-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal8">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab8/stunt.png" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 8</div>
                    </div>
                    <!-- Portfolio Item 9-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal9">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab9/Robot.png" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 9</div>
                    </div>
                    <!-- Portfolio Item 10-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal10">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab10/Sim.jpg" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 10</div>
                    </div>
                    <!-- Portfolio Item 11-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal11">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab11/Loc.jpg" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 11</div>
                    </div>
                    <!-- Portfolio Item 12-->
                    <div class="col-md-6 col-lg-4 mb-5 mb-lg-0">
                        <div class="portfolio-item mx-auto" data-bs-toggle="modal" data-bs-target="#portfolioModal12">
                            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
                                <div class="portfolio-item-caption-content text-center text-white"><i class="fas fa-plus fa-3x"></i></div>
                            </div>
                            <img class="img-fluid" style="height:260px;" src="assets/img/Lab12/Robot.png" alt="..." />
                        </div>
                        <div class="lab-text text-center mt-4">Lab 12</div>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- About Section-->
        <section class="page-section bg-primary text-white mb-0" id="about">
            <div class="container">
                <!-- About Section Heading-->
                <h2 class="page-section-heading text-center text-uppercase text-white">About</h2>
                
                <img class="center img-fluid rounded mb-2" style="height:300px; width:300px; padding-top: 1rem;" src="assets/img/Ronin4.jpg" alt="..." />
                
                <!-- Icon Divider-->
                <div class="divider-custom divider-light">
                    <div class="divider-custom-line"></div>
                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                    <div class="divider-custom-line"></div>
                </div>
                <!-- About Section Content-->
                <div class="row">
                    <p class="text-center lead" style="padding-left:15rem; padding-right:15rem;">
                        Hi, I'm Ronin! I'm an early-admit ECE MEng student at Cornell University. I am interested 
                        in machine learning, cloud computing, and embedded systems. In my free time, I enjoy 
                        playing badminton and tennis.
                    </p>
                </div>

            </div>
        </section>

        <!-- Copyright Section-->
        <div class="copyright py-4 text-center text-white">
            <div class="container"><small>Copyright &copy; Ronin Sharma 2022</small></div>
        </div>

        <!-- Portfolio Modals-->

        <!-- Portfolio Modal 1-->
        <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" aria-labelledby="portfolioModal1" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 1: The Artemis Board</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab1/Artemis.jpg" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to get familiar with the Artemis Nano board. I used the Arduino IDE to program 
                                        the board to perform simple actions such as blink, display the internal temperature, and detect certain frequencies. 
                                        This lab provided a solid refresher of using the Arduino IDE to develop simple programs that performed basic tasks.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p class="mb-4">USB C-to-C Cable</p>

                                    <h1>Setup</h1>
                                    <p class="mb-4">
                                        The first part of the lab involved setting up the Arduino IDE to program the 
                                        Artemis Nano. I had to install the Arduino Core for Apollo3. I used the IDE's 
                                        Board's Manager to install the Apollo3 Board Package. Then, I was able to select 
                                        this board within the IDE and upload code to it.
                                    </p>

                                    <h1>On-Board LED</h1>
                                    <p>
                                        The first program I uploaded to the board was a blink program (taken from the IDE's examples), 
                                        which utilized the on-board LED. The program made the LED turn on for one second, 
                                        turn off for one second, and continually repeated this pattern. Even though this 
                                        program was very simple, it helped to verify that I had installed the correct board package 
                                        and that I could correctly upload code to the board. Below is a video of the LED 
                                        blinking.
                                    </p>

                                    <video controls="controls" width="300" height="200" name="LED Blinking">
                                        <source src="assets/videos/BlinkVideo.mov">
                                    </video>

                                    <h1>Serial Monitor</h1>
                                    <p>
                                        The next part of the lab involved verifying that the Serial port works. Just like the blink code, 
                                        I used one of the example code files. This program simply printed text to the serial monitor. It 
                                        also allowed the user to enter text, and the program echoed that text back to the user. This simple 
                                        script allowed me to verify that the Serial port/monitor were working correctly, which is a good 
                                        sanity check since I will be using it frequently for debugging. Below is a video of the example code 
                                        running.
                                    </p>

                                    <video controls="controls" width="600" height="300" name="Serial Monitor">
                                        <source src="assets/videos/SerialMonitor.mov">
                                    </video>

                                    <h1>Temperature Measurement</h1>
                                    <p>
                                        The fourth part of the lab involved measuring the internal temperature of the Artemis Nano. The microcontroller 
                                        has an Analog-to-Digital converter to aid with this measurement. I experimented with varying the internal 
                                        temperature by pressing onto the chip. The video below shows the interal temperature gradually increasing 
                                        as a result of this action.
                                    </p>

                                    <video controls="controls" width="600" height="300" name="Temperature">
                                        <source src="assets/videos/Temperature.mov">
                                    </video>

                                    <h1>Frequency Measurement</h1>
                                    <p>
                                        The fifth part of the lab involved measuring frequency using the on-board pulse density microphone. I used the 
                                        example program that performed Fast Fourier Transform and identified the highest frequency. The video below shows 
                                        the resulting frequency of ambient noise, followed by a 500 Hz signal being played.
                                    </p>

                                    <video controls="controls" width="600" height="300" name="Microphone">
                                        <source src="assets/videos/Microphone_500Hz.mov">
                                    </video>

                                    <h1>Whistle Detection</h1>
                                    <p class="mb-4">
                                        The last part of the lab involved turning on the on-board LED when I whistled, and turning the LED off when I stopped 
                                        whistling. I modified the frequency measurement example code to achieve this behavior. First, I initialized variables 
                                        for the lowest and highest frequencies of my whistle. I used the previous program to detect what these frequencies were. 
                                        As the code snippet below indicates, if a frequency was within this range, I turned on the LED, otherwise I turned it off. 
                                    </p>
                                    
                                    <img src="assets/img/Lab1/WhistleDetection_Snippet1.png" height="100" width="400">
                                    
                                    <p class="mb-4">
                                        Lastly, I called this function within the main loop after the frequency was calculated, as shown below. 
                                    </p>

                                    <img src="assets/img/Lab1/WhistleDetection_Snippet2.png" height="100" width="400">

                                    <p class="mb-4">
                                    The video below shows an example of the LED turning on with a whistle and subsequently turning off when the whistle ends.
                                    </p>

                                    <video controls="controls" width="300" height="200" name="Whistle Detection">
                                        <source src="assets/videos/WhistleDetection.mov">
                                    </video>

                                    <br>
                                    <br>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 2-->
        <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" aria-labelledby="portfolioModal2" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 2: Bluetooth</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab2/USB_Bluetooth.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->

                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to setup a Bluetooth connection between the Artemis Nano and my computer. I used the 
                                        Arduino IDE to trasmit data wirelessly from the Artemis Nano to my computer, and Jupyter Lab to develop Python 
                                        code to transmit data wirelessly from my computer to the Artemis Nano. I was able to send basic messages 
                                        and commands to the Artemis Nano as well as receive simple responses. This lab provided a solid overview of 
                                        Bluetooth Low Energy.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p class="mb-4">USB C-to-C Cable</p>
                                    <p>Bluetooth 4.0 Low Energy Micro Adaptor</p>

                                    <h1>Setup</h1>
                                    <p class="mb-4">
                                        The first part of the lab involved setting up the Python environment and the Artemis Nano.
                                    </p>

                                    <h3>Computer Setup</h3>
                                    <p class="mb-4">
                                        First, I ensured that I had Python 3.9 installed along with a pip (Python package manager) version 
                                        of at least 21.0. Next, I setup a virtual environment for this lab. This allowed me to maintain the correct 
                                        versions for this lab's Python packages, and helped ensure they didn't conflict with other packages 
                                        I had installed. After activating the virtual environment, I installed the following packages using pip: 
                                        <code>numpy, pyyaml, colorama, nest_asyncio, bleak, jupyterlab</code>. Lastly, I downloaded the Lab 2 Codebase 
                                        from Cornell Box and verified that I was able to start the Jupyter server.
                                    </p>

                                    <h3>Artemis Nano Setup</h3>
                                    <p class="mb-4">
                                        I had to install the ArduinoBLE library, and used the IDE's library manager to do this. I ran the provided code 
                                        to obtain the Artemis Nano's MAC address, which can be seen below.
                                        
                                        <img src="assets/img/Lab2/ArtemisMACAddress.png" height="150" width="500">

                                        <br>
                                    
                                        I had to use this MAC address as a final configuration step for BLE. The provided Python code had a 
                                        <code>connection.yaml</code> file, which had a field for the Artemis Nano's MAC address. I replaced 
                                        this field's value with the MAC address displayed by the serial monitor. After doing this, I was able to 
                                        connect to the Artemis Nano from my computer, and the serial monitor verified this connection.

                                        <img src="assets/img/Lab2/SerialMonitor_Connection.png" height="200" width="400">
                                    </p>

                                    <h3>ECHO Command</h3>
                                    <p class="mb-4">
                                        This first lab task was the ECHO command. This command involved sending a message from my computer 
                                        to the Artemis Nano and having the Nano respond with an augmented message. For example, my computer 
                                        could send <code>Hello</code> and the Nano respond would respond with <code>Received Message: Hello</code>. The 
                                        provided lab code had functions for sending the command and processing the response, so I only had to implement 
                                        the code on the Arduino side to receive the command and send the response. The ArduinoBLE library and provided 
                                        lab code helped initiate this process. It had the logic for decoding the command and extracting the message (as a string). 
                                        I added the logic for constructing and sending the response. As shown in the image below, I had to clear the transmission 
                                        string, add the appropriate text, which was the augmented string, and finally write this string to the BLE string characteristic.
                                        <br>
                                        <img src="assets/img/Lab2/ECHO_function.png" height="350" width="400">
                                        <br>

                                        The two images below show the Python code and output response as well as the Arduino's serial monitor output, which indicate 
                                        that this command works correctly.
                                        <br>
                                        <img src="assets/img/Lab2/ECHO_Python.png" height="300" width="350">
                                        <br>
                                        <img src="assets/img/Lab2/ECHO_SerialMonitor.png" height="100" width="500">
                                    </p>


                                    <h3>SEND_THREE_FLOATS Command</h3>
                                    <p class="mb-4">
                                        The second lab task was the SEND_THREE_FLOATS command, and this was slightly simpler than the previous command. 
                                        It only entailed sending three floats from my computer to the Artemis Board, and printing these values to the serial 
                                        monitor. The implementation, as show below, was nearly identical to the previous command. However, the values were floats 
                                        instead of strings, and I didn't have to construct a response message.
                                        <br>
                                        <img src="assets/img/Lab2/SENDTHREEFLOATS.png" height="350" width="400">
                                        <br>
                                        The two images below show the Python code for sending the command and the serial monitor output ensuring that 
                                        the command functioned correctly.
                                        <br>
                                        <img src="assets/img/Lab2/SENDTHREEFLOATS_Python.png" height="250" width="500">
                                        <br>
                                        <img src="assets/img/Lab2/SENDTHREEFLOATS_Arduino.png" height="175" width="350">
                                    </p>

                                    <h3>Notification Handler</h3>
                                    <p class="mb-4">
                                        The next part of the lab involved setting up a notification handler to receive floats sent by the Artemis board. For the 
                                        previous command, I would have to explicitly check if the Artemis board sent a response, which can become fairly tedious. The handler 
                                        (shown below) took a GATT characteristic's uuid and received data value as inputs, and simply updated a global variable to be this 
                                        value and then printed it out and returned it.
                                        <br>
                                        <img src="assets/img/Lab2/Notification_Handler.png" height="200" width="400">
                                        <br>
                                        Lastly, I started the nofications by binding the float GATT characteristic to the handler function, as shown below. I had to use the 
                                        <code>stop_notify</code> function, which was provided, to stop the notifications.
                                        <br>
                                        <img src="assets/img/Lab2/Notification_Handler_Running.png" height="300" width="300">
                                        <br>
                                        These values make sense, since as long as the connection exists, the Artemis Nano Board is incrementing the float value by <code>0.5</code> 
                                        and then sending it (as shown by the two code segments below).
                                        <br>
                                        <img src="assets/img/Lab2/Write_Data_Function.png" height="200" width="250">
                                        <br>
                                        <img src="assets/img/Lab2/Increment_5.png" height="300" width="300">
                                    </p>

                                    <h3>Different Data Transmission Methods</h3>
                                    <p class="mb-4">
                                        The function requirements are based on their names, so <code>receive_float()</code> requires a float and <code>receive_string()</code> 
                                        requires a string. To receive a float value in Python, nothing needs to be done if <code>receive_float()</code> is used, but type 
                                        conversion from string to float is required if <code>receive_string()</code> is used. Additionally, a string, which is comprised 
                                        of characters, requires more bits than floats. As a result, larger values and more precise values can be used by <code>receive_float</code> 
                                        compared to <code>receive_string</code>.

                                        <br>
                                        <br>

                                        Additionally, the implementations of the two functions differ as <code>receive_float()</code> uses the float GATT Characteristic while 
                                        <code>receive_string()</code> uses the C-String GATT Characteristic. They also use different functions to parse the data. Specifically, 
                                        <code>receive_float()</code> uses the <code>unpack()</code> method from the struct module on the byte array, while <code>receive_string()</code> 
                                        uses the byte array object's <code>decode()</code> method.

                                    </p>

                                    <h3>Effective Data Rate</h3>
                                    <p class="mb-4">
                                        The next part of the lab involved calculating the effective data rate. I used the ECHO command to send 
                                        a message from my computer to the Artemis board and then used the <code>receive_string()</code> method 
                                        to obtain the response sent from the Artemis board to my computer. I used Python's <code>time</code> 
                                        module to collect the time before sending the message, collect the time after receiving the message, and 
                                        then calculated the elapsed time by taking the difference. I used Python's <code>getsizeof()</code> function 
                                        to obtain the number of bytes in the two messages, and then calculated the data rate by dividing the total 
                                        message size by the time elapsed. I calculated the data rate for four different messages of various sizes, and 
                                        for each message I averaged the results from ten trials. The image below contains the Python code for this part.
                                        <br>
                                        <img src="assets/img/Lab2/Effective_Data_Rate_Python.png" height="500" width="500">
                                        <br>
                                        I used Python's <code>matplotlib</code> module to plot the results, as shown below. As the data size increased, 
                                        the data rate also generally increased. There was a slight decrease from 117 to 125 bytes, but this is most likely 
                                        an outlier or negligible. I believe the trend indicates that the setup overhead dominates at smaller data sizes, and 
                                        similarly doesn't have a major effect at the larger data sizes.
                                        <br>
                                        <img src="assets/img/Lab2/Effective_Data_Rate_Plots.png" height="500" width="500">

                                    </p>

                                    <h3>Reliability</h3>
                                    <p class="mb-4">
                                        The last part of the lab involved determined the reliability of the Artemis Nano. I utilized the float 
                                        notification handler I wrote previously to perform this task. The provided Arduino code 
                                        sent a float every time the timer exceeded a value, specified by the variable <code>interval</code>. The larger 
                                        this variable, the longer the time between successive floats. I attempted to exceed the data rates I calculated 
                                        in the previous part of the lab by significantly decreasing the value of <code>interval</code>. I started by making it
                                        <code>10</code>, then <code>1</code>, then <code>0.0001</code>, but the notification handler kept reading every value, which 
                                        included consecutive increments of <code>0.5</code>, and this was surprising to me since I expected some data to be dropped. 
                                        Even when I set interval to <code>0</code>, no data was dropped, which indicated that the Artemis Nano is very reliable. 

                                        <br>
                                        <br>
                                        The image below shows the receiver (computer) output when <code>interval</code> is set to <code>0</code>. As I mentioned previously, 
                                        I utilized the notification handler again and disabled it after two seconds to limit the output.
                                        <br>
                                        <img src="assets/img/Lab2/Reliability_Zero_Interval.png" height="450" width="500">
                                    
                                    </p>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 3-->
        <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" aria-labelledby="portfolioModal3" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 3: Sensors</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab3/TOF_Sensor.jpg" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to add two types of sensors to the robot: Time-of-Flight (ToF) Sensor 
                                        and Inertial Measurement Unit (IMU). I connected these sensors to the Artemis Nano Board and verified 
                                        that they were connected properly by running basic scripts. I developed more complicated scripts to 
                                        calibrate and test many features of both sensors. By the end of the lab, I had a robot with 
                                        fully-functional ToF sensors and an IMU.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Two 4m Time-of-Flight Distance Sensors</p>
                                    <p>9DOF Inertial Measurement Unit Sensor</p>
                                    <p>Qwiic Connector</p>
                                    <p>Ruler</p>

                                    <h1>Prelab</h1>
                                    <p class="mb-4">
                                        Prior to the lab, I researched the two types of sensors. I skimmed both of their manuals and datasheets. 
                                        I also planned out some of the sensor integration aspects. I decided to use permanent soldered connections 
                                        for both sensors to ensure that the sensors remain available throughout the high accelerations. I planned 
                                        out the wire lengths as well. I planned to have one ToF sensor in the front of the robot, one of the side, and 
                                        the IMU near the back of the robot to limit electromagnetic interference.
                                    </p>

                                    <h1>Time-of-Flight Sensors</h1>

                                    <h3>Setup</h3>
                                    <p class="mb-4">
                                        First, I soldered one sensor and connected it to the Artemis Nano by using the Qwiic Connector, which 
                                        connected directly to the Artemis. Then I daisy-chained a second ToF sensor. For the second sensor, I also 
                                        had to utilize the XSHUT pin. Since I'm connecting two identical sensors on the same I2C bus, their addresses 
                                        are the same. I had to use the XSHUT pin to shut one sensor down and restart it with a different address.
                                        
                                        The final wiring is depicted below.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/TOF_Final.png" height="350" width="400">

                                        <br>
                                        <br>

                                        Next, I had to install the <code>SparkFun VL53L1x 4m Laser Distance Sensor</code> library using the Arduino 
                                        IDE's library manager.
                                    </p>

                                    <h3>Sensor Experimentation</h3>
                                    <p class="mb-4">
                                        As I mentioned previously, I had to change the address of one of the ToF sensors. I turned one sensor off, 
                                        but forcing its XSHUT pin low, then I changed the address for the sensor still on by using the 
                                        <code>setI2CAddress()</code> function, and then I wrote a digital high to the XSHUT pin to turn the other 
                                        sensor back on. The code snippet below reflects these actions.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Change_Address.png" height="350" width="400">

                                        <br>

                                        I ran the example I2C Wire code to check if the I2C channel address matched what I expected. However, instead of 
                                        the two sensor addresses being printed, all addresses were printed. This is a problem we established in lab, so I 
                                        used other scripts to check if the sensors were working.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Addresses_2Sensors.png" height="400" width="450">

                                        <br>
                                        <br>

                                        Instead, I used the read distance example. As the name suggests, this script displays the distance detected by one 
                                        ToF sensor. Since I had already added the second sensor and changed the address, all I had to add was the logic 
                                        for obtaining the distance for it and displaying it. I utilized the same code that was provided and modified it 
                                        to reference the second sensor object. Below is the code modification and the output of the serial monitor showing 
                                        both sensors operating correctly.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Two_Distance_Sensor_Code.png" height="500" width="550">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Example_Distance_Output.png" height="350" width="400">

                                        <br>
                                        <br>

                                        <video controls="controls" width="300" height="300" name="Two Sensor Readings">
                                            <source src="assets/videos/Lab3/TwoSensorReadings.mov">
                                        </video>

                                        <br>
                                        <br>

                                        Next, I explored the three distance modes (short, medium, and long) that the ToF sensor has. The short distance 
                                        mode is good for sensing immediate obstacles. However, if there's the occasional larger distance that needs to 
                                        be detected, this mode would cause a problem since it wouldn't be able to detect it (it has a max of 1.3m). 
                                        The long distance mode is good for checking that there is a lot of open space in front of the robot. It might 
                                        not be as helpful if there are abrupt close obstacles since this would lead to fluctuations in close and far distance 
                                        sensing. This mode is also more error prone when there are inconsistencies in the surrounding environment. The medium 
                                        distance mode should be the happy middle of the previous two modes. A slight disadvantage is that it's not specialized 
                                        in short or long distances. Ultimately, I chose the short distance mode for the robot because I believe we will mainly want 
                                        to detect nearby obstacles. Given the size of the robot, this mode will create a large sensing area around the robot.

                                        <br>
                                        <br>

                                        The code snippet below shows how I set the distance mode for both sensors.

                                        <img src="assets/img/Lab3/SetDistanceMode.png" height="250" width="400">

                                        <br>
                                        <br>

                                        Then, I tested the accuracy of this distance mode. For each measurement, I averaged 25 values and used <code>millis()</code> 
                                        to find the average ranging time. The images below include the graph and the code used to generate that graph. The blue line 
                                        represents sensor 1, the orange line represents sensor 2, and the green line represents the line <code>y = x</code>. Overall, 
                                        the sensors weren't too far off and measured distances were fairly close to what I expected.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/SensorAccuracyCode.png" height="450" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/SensorAccuracyPlot.png" height="450" width="500">

                                        <br>
                                        <br>

                                        I experimented with different surfaces. When I used the sensor on different colors and other flat surfaces (wood, cloth), 
                                        the accuracy didn't change significantly. Even when I used it to detect uneven/bumpy surfaces (small pile of objects, 
                                        crumpled up paper), the values still ended up being fairly consistent. This demonstrates that these sensors are fairly 
                                        robust.
                                        
                                    </p>

                                    <h3>Infrared Transmission</h3>
                                    <p class="mb-4">
                                        The ToF sensors utilize laser pulses to measure distances. Infrared distance sensors measure the reflected infrared (IR) light, 
                                        and then use it to estimate the location of an object. Specifically, the angles of reflected beams are analyzed.

                                        <br>
                                        <br>

                                        There are active and passive IR sensors. Active sensors are able to emit and detect IR radiation, while passive sensors 
                                        are only able to detect IR radiation. If I was to use an IR distance sensor on the robot, I would use an active IR sensor 
                                        so that I could detect any type of obstacles, since it isn't common for objects to emit significant IR radiation. 

                                        <br>
                                        <br>
                                        
                                        Generally, IR distance sensors are faily small and are capable of measuring distances to complex surfaces and objects. 
                                        One problem with infrared sensors is that the light conditions can significantly affect the performance of the sensor.
                                    </p>

                                    <h3>Timing Budget</h3>
                                    <p class="mb-4">
                                        I experimented with the timing budget of the ToF sensor. I used the manual to identify functions I could use to modify 
                                        the timing budget. I noticed the most notable changes when I used the function <code>setTimingBudgetInMs()</code>. 
                                        This function set the time needed to perform one measurement. A larger value means less frequent measurements, but 
                                        even when I tried larger values, I didn't notice any significant changes in my distance calculations. 
                                        When I set it to the minimum (<code>20 ms</code>), I was able to more than halve the ranging time (shown below). 
                                        The images below include the code snippet to modify the timing budget and the observed results.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/SmallestTimingBudget.png" height="250" width="400">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/SmallestTimingBudget_Output.png" height="400" width="500">
                                    </p>

                                    <h3>"Signal and Sigma"</h3>
                                    <p class="mb-4">
                                        The last aspect of the ToF sensors that I analyzed was their "signal and sigma" parameters. These parameters specify if 
                                        the sensor's readings are valid, which allowed me to discard invalid measurements. I used the minimum timing budget 
                                        (<code>20 ms</code>) with the short distance mode, and abruptly changing the distance to an object didn't impact the range 
                                        status (it remained good). However, the signal rate did fluctuate after these changes. The video below reflects these 
                                        trials.

                                        <video controls="controls" width="400" height="300" name="Status and Rate">
                                            <source src="assets/videos/Lab3/StatusAndRate.mov">
                                        </video>

                                        <br>
                                        <br>

                                        At the end of the video, the range status changed because the distance exceeded the maximum <code>1.3m</code> of this mode, which was a 
                                        result of me trying to push the fluctuation limits (practically <code>0.0m</code> to <code>1.3m</code>). I was surprised 
                                        by this behavior since I expected rapid fluctuations to cause the signal to fail, at least occasionally. I'll have to check 
                                        this again prior too completing future lab tasks, and possibly increase the timing budget accordingly.
                                    </p>

                                    <h1>Inertial Measurement Unit</h1>

                                    <h3>Setup</h3>
                                    <p class="mb-4">
                                        First, I soldered the IMU's connections, which were also daisy chained to the previous ToF sensors. The soldered sensor is depicted 
                                        below.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/IMU_Final.png" height="350" width="400">

                                        <br>
                                        <br>

                                        Then, I installed the appropriate Arduino library: <code>SparkFun 9DOF IMU Breakout - ICM 20948</code>. I ran the same provided code 
                                        to display the sensor's I2C address, but this just printed all addresses since multiple sensors were connected.

                                        <br>
                                        <br>

                                        I ran the basic example which displayed various sensor values. I modified the script and set <code>AD0_VAL</code> to 0 because the ADR 
                                        jumper is closed. By default, the ADR jumper is open, which requires this value to be 1, but that doesn't work correctly for my circuit 
                                        since the ADR jumper is closed. The video below shows the changes based on accelerations in the x, y, and z directions, respectively. 
                                        Rotating the IMU about each axis increased the Gyroscope's values for that sensor. I added a one second delay between each display 
                                        to make it easier to analyze the changes on the serial monitor output.

                                        <br>
                                        <br>

                                        <video controls="controls" width="400" height="300" name="IMU">
                                            <source src="assets/videos/Lab3/IMU.mov">
                                        </video>
                                        
                                    </p>

                                    <h3>Accelerometer</h3>
                                    <p class="mb-4">
                                        Next, I used the accelerometer data to compute pitch and roll. I used the formulas from lecture and focused on the output values 
                                        at <code>-90, 0, and 90</code> degrees for pitch and roll. The image below shows the code used to perform this calculation.

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab3/Pitch_Roll_From_Acc.png" height="350" width="400">
                                        <br>
                                        
                                        The images below show the output calculations for pitch at -90, 0, and 90 degree angles, respectively.

                                        <br>
                                        <br>
                                        <img src="assets/img/Lab3/Pitch_-90.png" height="350" width="400">
                                        <br>
                                        <hr>
                                        <img src="assets/img/Lab3/Pitch_0.png" height="350" width="400">
                                        <br>
                                        <hr>
                                        <img src="assets/img/Lab3/Pitch_90.png" height="350" width="400">
                                        <br>
                                        <br>

                                        The images below show the output calculations for roll at -90, 0, and 90 degree angles, respectively.

                                        <br>
                                        <br>
                                        <img src="assets/img/Lab3/Roll_-90.png" height="350" width="400">
                                        <br>
                                        <hr>
                                        <img src="assets/img/Lab3/Roll_0.png" height="350" width="400">
                                        <br>
                                        <hr>
                                        <img src="assets/img/Lab3/Roll_90.png" height="350" width="400">
                                        <br>
                                        <br>

                                        For both pitch and roll, the expected values were <code>-1.57 (-pi/2), 0, and 1.57 (pi/2)</code>, which is fairly 
                                        close to the computed values. The maximum error is <code>0.20</code>, which is less than <code>15%</code> error.

                                        <br>
                                        <br>

                                        Then, I plotted the frequency response as a result of tapping on the sensor. I referenced this 
                                        <a href = "https://alphabold.com/fourier-transform-in-python-vibration-analysis/">resource</a> for example Python code. 
                                        I updated the Arduino code to print out the pitch and time values.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Pitch_Time_Values.png" height="450" width="500">

                                        <br>
                                        <br>

                                        Then, I loaded this data into Python and performed FFT.
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/FFT.png" height="400" width="450">

                                        <br>
                                        <br>

                                        Below are the resulting time domain and frequency response plots, respectively.

                                        <img src="assets/img/Lab3/Pitch_Time_Domain.png" height="450" width="500">
                                        <img src="assets/img/Lab3/Pitch_Frequency_Response.png" height="450" width="500">

                                        <br>
                                        <br>

                                        The goal of this analysis was to identify a cutoff frequency for the low-pass filter to help eliminate noise.
                                        A higher cutoff frequency implies that rapid movements above the high frequency should not affect the pitch values. 
                                        The frequency response plot didn't reflect a lot of noise readings, so I just used a cutoff frequency of 50 Hz since 
                                        my future measurements will likely not be greater than 50 Hz. The code snippet below shows the calculation of the 
                                        alpha value (<code>0.4652</code>) for the filter (based on the formulas in the lecture slides).

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Pitch_Alpha_Calculation.png" height="450" width="500">

                                        <br>
                                        <br>

                                        When the complimentary low pass filter utilized the calculated alpha value of <code>0.4652</code> it didn't have 
                                        much of an impact on the results as the plots from the serial plotter looked fairly similar. The blue and green 
                                        lines are the acceleration values calculated from the accelerometer, and the red and orange lines are the filtered values.

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab3/CompFilter_alpha_46.png" height="450" width="500">

                                        <br>
                                        <br>

                                        However, using an alpha value of <code>0.14</code> did have an impact. The new plot showed that the pitch and roll values 
                                        calculated from the accelerometer were sensitive to taps at <code>t = 125, t = 175</code>, but the filtered values were 
                                        not.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/CompFilter_alpha_14.png" height="450" width="500">

                                    </p>

                                    <h3>Gyroscope</h3>
                                    <p class="mb-4">
                                        Next, I used the gyroscope data to compute pitch, roll, and yaw. Again, I used the formulas from lecture to perform these 
                                        calculations. The gyroscope calculated pitch and roll values were significantly different from the accelerometer's calculated 
                                        values and the low pass filtered values. The outputs of the Gyroscope's calculations are below.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Gyro_YPR.png" height="400" width="600">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Gyroscope_1a_dt30.png" height="400" width="600">

                                        <br>
                                        <br>

                                        In the plot above, the green and grey lines are the Gyroscope readings. They tend to drift away from zero. I experimented 
                                        with lowering the sampling frequency by a factor of ten, and this made the error even worse.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Gyroscope_1a_dt300.png" height="450" width="500">

                                        <br>
                                        <br>

                                        Next, I tried to improve the accuracy and stablility of the pitch and roll values by implementing a complimentary filter. 
                                        For this filter, I started with the sampe alpha value as the one I used for the acceleration filter (<code>0.14</code>), 
                                        since it worked well for that. I also reverted back to the original sampling frequency, which was the sampling frequency 
                                        that had the least error for the originial gyroscope calculations. This resulted in less drift, with the fluctuations in 
                                        the middle of the plot a result of rapid rotations.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/Gyro_Comp_Filter_alpha04.png" height="400" width="650">
                                        
                                    </p>

                                    <h3>Magnetometer</h3>
                                    <p class="mb-4">
                                        The last part of the lab involved using the magnetometer. I converted the data from the magnetomer into yaw angle by using 
                                        the formulas presented in lecture. The image below shows sample output data.

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab3/ConvertingMagnetometerDataToYaw.png" height="350" width="500">

                                        <br>
                                        <br>

                                        I noticed some interesting trends in the sensor data. The magnetometer's data didn't fluctuate a lot. Its values would 
                                        change after time intervals, and sometimes remain constant for a substantial period of time. I attempted to find 
                                        the magnetic north, at which one component should be zero and another component should be at a maximum. The graph 
                                        below plots the output data while I attempted to find magnetic north.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab3/MagnetometerOutput.png" height="350" width="400">

                                        <br>
                                        <br>

                                        In the graph, one component's magnitude is somewhat close to 0 and another is around 35 mT. As I varied the pitch, 
                                        the magnetometer's values didn't change significantly. Overall, I expected to see more fluctuations in the data, but 
                                        this is the output I observed from the IMU.
                                    </p>



                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 4-->
        <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" aria-labelledby="portfolioModal4" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 4: Characterize Your Car</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab4/Car_Top.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to understand the capabilities of the RC car. I performed the necessary 
                                        steps to power the Artemis Nano Board with a battery. Then I performed simple measurements and more 
                                        complicated experimental analyses to learn about the car's abilities and limitations.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Battery Packs (600mAh and 850 mAh)</p>
                                    <p>2mm JST Connector</p>
                                    <p>RC Car</p>
                                    

                                    <h1>Artemis Nano Setup</h1>
                                    <p class="mb-4">
                                        First, I setup the Artemis Nano to be battery powered. This allowed me to use the Artemis untethered to my computer. 
                                        I soldered the 600mAh battery's connector to the 2mm JST connector, which fit into the Artemis. I was able to charge the 
                                        battery by connecting the Artemis to my computer by using the USB C-to-C cable.
                                    </p>

                                    <h1>Simple Measurements</h1>
                                    <p class="mb-4">
                                        I started by measuring the dimensions of the car. The complete dimensions are 18 cm x 14.5 cm x 8 cm. The diameter of the wheel 
                                        is 8.5 cm. Here are images of the top and bottom of the car.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab4/Car_Top.png" height="400">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab4/Car_Bottom.png" height="400">

                                        <br>
                                        <br>
                                        
                                        When using the ToF sensors in future labs, I may want to identify the location of the robot. Ideally, I'd want to 
                                        know the center of the robot. However, the ToF sensors will not be located at the center of the robot, and instead one will be 
                                        on the front and the other will be on the side. By measuring the dimension of the robot, for the front ToF sensor, I can add the 
                                        distance detected to half of the length of the car. Similarly, for the side ToF sensor, I can add the distance detected to half 
                                        of the width of the car. The IMU's accelerometer will be used to calculate distance traveled, so using that data in addition to 
                                        these measurements will allow me to pinpoint the center of the robot.

                                        <br>
                                        <br>

                                        I also measured the small compartment on the car which will be used to store some components such as the Artemis Nano Board, which 
                                        is depicted below.
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab4/Compartment.png" height="400">

                                        <br>
                                        <br>

                                        I can probably keep some components in addition to the Artemis Board in the compartment, and can use this measurement to plan 
                                        which components will fit. The dimensions of the compartment were 6.5 cm x 3.5 cm x 2.5 cm. However, I plan to keep the top 
                                        open so the height of this compartment doesn't matter.

                                        <img>

                                        <br>
                                        <br>

                                        Lastly, I measured the battery life time. This will allow me to plan for future labs, since I will know how long I can operate the 
                                        robot without needing to change the battery. I experimented with five batteries, and the life times were between 8-9 minutes.
                                    </p>

                                    <h1>Experimental Analyses</h1>

                                    <i>Collaborator: Chris Chan</i>

                                    <h3>Straight Line Movement</h3>
                                    <p class="mb-4">
                                        In future labs, the robot will be moving a lot. I believe one important aspect will be to keep the robot as straight as possible 
                                        when it is moving forward. I will end up using PID to help with this, but I wanted to assess how straight the robot moves on its 
                                        own. I tested moving the car straight on two surfaces: a carpet and a couch. I tried to pick fairly extreme types of surfaces 
                                        to stress test the car's movement. It moved fairly straight on the carpet, with some slight angular movements, but it was much 
                                        more angled on the couch. Hopefully I'll be able to use better surfaces for the later labs, but PID will also help with straightening 
                                        out the motion.

                                        <br>
                                        <br>

                                        <video controls="controls" height="400" name="Movement Carpet">
                                            <source src="assets/videos/Lab4/Move_Carpet1.mov">
                                        </video>

                                        <br>
                                        <br>

                                        <video controls="controls" height="400" name="Movement Couch">
                                            <source src="assets/videos/Lab4/Move_Couch1.mov">
                                        </video>
                                    </p>

                                    <h3>Turning Mechanism</h3>
                                    <p class="mb-4">
                                        Next, I explored how well the car can turn around its own axis. When it detects obstacles in future labs, it will definitely 
                                        need to maneuver around them. For instance, an obstacle can suddenly appear, and the robot will need to immediately turn to 
                                        avoid it. For this reason, I wanted to check how fast and reliable the car can turn. The two videos below show the robot turning 
                                        on two different surfaces.

                                        <br>
                                        <br>

                                        <video controls="controls" height="400" name="Turning Table">
                                            <source src="assets/videos/Lab4/Spin_Table1.mov">
                                        </video>

                                        <br>
                                        <br>

                                        <video controls="controls" height="400" name="Turning Carpet">
                                            <source src="assets/videos/Lab4/Turning1.mov">
                                        </video>

                                        <br>
                                        <br>

                                        In both scenarios, the robot does move while turning, and this is much more apparent in the carpet turning as compared to the table turning. 
                                        However, I don't believe this will be a big problem because I don't believe the robot will need to replicate this action. It may need to perform a 
                                        180 degree turn, but it will not need to consistently turn for an elongated period of time. As a result, the apparent drift from continuously 
                                        turning shouldn't be a problem moving forward.
                                    </p>

                                    <h3>Car Stunts/Tricks</h3>

                                    <h4>Ramp</h4>
                                    <p class="mb-4">
                                        Next, I wanted to test how well I can operate the car manually. This allowed me to understand the "upper limit" of what the robot will be 
                                        able to do. It also allowed me to think about the commands the Artemis will need to perform these types of actions. Overall, I learned 
                                        that it is fairly simple to have the robot do tricks, since they only require a few combinations of commands (forward/backward and vice versa).

                                        <br>
                                        <br>

                                        I started by seeing if I could drive the car up a fairly steep incline. I used wooden planks with velcro to create the incline. I tried this 
                                        several times but didn't have a ton of success. Usually, the car would make it up part of the ramp, but then it would fall off the side of the 
                                        ramp. The following two videos show failed attempts to get to the top of the ramp.

                                        <br>
                                        <br>

                                        <video controls="controls" height="400" name="Ramp Fail 1">
                                            <source src="assets/videos/Lab4/Ramp_Fail1.mov">
                                        </video>

                                        <br>
                                        <br>

                                        <video controls="controls" height="400" name="Ramp Fail 2">
                                            <source src="assets/videos/Lab4/Ramp_Fail2.mov">
                                        </video>

                                        <br>
                                        <br>

                                        Eventually, I was able to get the robot to the top of the ramp.

                                        <br>
                                        <br>

                                        <video controls="controls" height="400" name="Ramp Success">
                                            <source src="assets/videos/Lab4/Ramp_Success.mov">
                                        </video>

                                        <br>
                                        <br>
                                    </p>
                                    
                                    <h4>Flips</h4>
                                    <p class="mb-4">
                                        Next, I experimented with getting the robot to flip. I was able to do this fairly easily. I moved the robot forward and 
                                        then quickly flipped the direction, which caused it to flip. The video below demonstrates this behavior.

                                        <br>
                                        <br>

                                        <video controls="controls" width="300" height="200" name="Flips">
                                            <source src="assets/videos/Lab4/Flips.mov">
                                        </video>

                                        <br>
                                        <br>

                                        I also tried to get the car to land on its side following a flip. I achieved this by moving the robot forward, then quickly 
                                        changing directions, and then I quickly turned the robot slightly to the right. This didn't always work since sometimes the 
                                        robot would just fall over. The video below demonstrates a working example of the robot ending up on its side.

                                        <br>
                                        <br>

                                        <video controls="controls" width="300" height="200" name="Flips Side">
                                            <source src="assets/videos/Lab4/Flips_Side.mov">
                                        </video>

                                        <br>
                                        <br>

                                        The video below shows a full suite of stunts.

                                        <br>
                                        <br>

                                        <video controls="controls" width="800" name="Flips Side">
                                            <source src="assets/videos/Lab4/Flips_and_Tricks2.mov">
                                        </video>
                                    </p>

                                    <h3>Launching Distance</h3>
                                    <p class="mb-4">

                                        Lastly, I measured the maximum launching distance of the car. I started the car at the edge of a circular table and then launched 
                                        it towards a couch. The table had a larger height than the couch. Here are the distances and heights of the setup.

                                        <p>Height of table: 70 cm</p>
                                        <p>Diameter of the table (distance traveled by the car): 118 cm</p>
                                        <p>Height of the couch: 46 cm</p>
                                        
                                        <br>
                                        <br>
                                        
                                        The image below depicts the car at the edge of the table prior to the launch.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab4/Launch_Setup.png" height="300" width="300">

                                        <br>
                                        <br>

                                        I tested various distances to identify how far the car could travel. The four videos below show the success at covering 76 and 78 cm, along 
                                        with the failure to cover 80 and 82 cm, respectively.

                                        <br>
                                        <br>

                                        <video controls="controls" width="300" height="200" name="Launch 76">
                                            <source src="assets/videos/Lab4/Launch_76_Success1.mov">
                                        </video>

                                        <br>
                                        <br>

                                        <video controls="controls" width="300" height="200" name="Launch 78">
                                            <source src="assets/videos/Lab4/Launch_78_Success1.mov">
                                        </video>

                                        <br>
                                        <br>

                                        <video controls="controls" width="300" height="200" name="Launch 80">
                                            <source src="assets/videos/Lab4/Launch_80_Fail1.mov">
                                        </video>

                                        <br>
                                        <br>

                                        <video controls="controls" width="300" height="200" name="Launch 82">
                                            <source src="assets/videos/Lab4/Launch_82_Fail1.mov">
                                        </video>
                                        
                                        <br>
                                        <br>

                                        I wanted to test this because I didn't have a lot of success with driving the car up a ramp. Even though this wasn't the same, 
                                        this allowed me to learn more about manually operating the car. Even though I probably won't directly use this information 
                                        in later labs, it was a lot of fun to see how far the car could travel. 
                                    </p>


                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 5-->
        <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" aria-labelledby="portfolioModal5" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 5: Open Loop Control</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab5/Robot2.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->

                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to setup open loop control of the RC car. I performed the necessary steps 
                                        to move the car using signals sent by the Artemis board. I was able to make the car move in a straight 
                                        line as well as perform simple turns.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Battery Packs (600mAh and 850mAh)</p>
                                    <p>2 dual motor drivers</p>
                                    <p>RC Car</p>
                                    
                                    <h1>Setup</h1>
                                    <p class="mb-4">
                                        In the previous lab, I demonstrated that I could manually control the RC car. In this lab, I had to modify 
                                        the car to allow the Artemis board to control it. One of the primary considerations was the speed of the 
                                        car, hence the course name: <i>Fast</i> Robots. To increase the speed of the car, I parallel coupled each 
                                        motor driver. This allowed me to double the amount of current delivered to the motor. I had to use PWM pins 
                                        on the Artemis board to control the motor drivers. I referenced the pinout diagrams 
                                        <a href="https://cdn.sparkfun.com/assets/5/5/1/6/3/RedBoard-Artemis-Nano.pdf">here</a> to determine which 
                                        pins support PWM on the Artemis Nano. Based on the motor driver's documentation, which can be found 
                                        <a href="https://www.pololu.com/product-info-merged/2130">here</a>, I decided to hook up the motor drivers 
                                        as shown below.

                                        <br>

                                        <img src="assets/img/Lab5/MotorDriverConnections.png" width="300">

                                        <br>

                                        I had to solder the majority of the connections. I also had to disassemble some parts of the RC car. Specifically, 
                                        I removed the blue shell, chassis LEDs, and control PCB. Lastly, I mounted all components on the car (sensors, 
                                        motor drivers, Artemis Nano). The images below depict everything assembled.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/Robot1.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/Robot2.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/Robot3.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/Robot4.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/Robot5.png" width="300">
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/Robot6.png" width="300">

                                        
                                    </p>

                                    <h1>Basic Motor Operation</h1>
                                    <p class="mb-4">
                                        To test the operation of the motors, I placed the car on its side and experimented with running the motor in 
                                        both directions. The code snippet below shows how I initialized the motor driver's PWM pins, and used <code>analogWrite</code> 
                                        to write the PWM signal values.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/testOneMotor.png" width="300">

                                        <br>
                                        
                                        The two videos below show the expected functionality of the wheels turning in both directions.

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/eNZSYNG58M0" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Otu0xqRGlsI" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>
                                        
                                        <br>

                                        Then, I expanded this to two motors. I initialized the additional two PWM pins, as shown by the code snippet below.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/setupTwoMotorPins.png" width="300">

                                        <br>
                                        <br>

                                        Similar to before, I had to initialize the additional pins, as shown below.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/setupTwoMotorPins2.png" width="300">

                                        <br>
                                        <br>

                                        I then replicated the <code>analogWrite</code> code for the second motor, as shown below.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/PWMTwoMotors.png" width="300">

                                        <br>
                                    </p>

                                    <h1>Basic Car Motion</h1>

                                    <h3>Lower Limit of the Motor</h3>
                                    <p class="mb-4">
                                        Next, I determined the lowest PWM signal I could send to the motor drivers such that the robot still moved on the 
                                        ground. I simply varied the PWM value written to pins A2, A3, A14, and A16. I tested moving 
                                        the robot on a flat table with a similar amount of friction to the lab floor. I discovered that the lowest PWM signal 
                                        at which the robot was still able to move was 40. The video below shows the robot moving at this speed.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/wch7PLO4Bdg" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>
                                        
                                    </p>

                                    <h3>Straight Line Motion</h3>
                                    <p class="mb-4">
                                        Next, I made the robot move in a straight line. I had to use different PWM values to achieve straight line motion. Specifically, 
                                        I had to offset the two motors' PWM values by 5. The code snippet below depicts this logic.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/forwardStraight.png" width="300">
                                        
                                        <br>
                                        <br>

                                        The video below shows the robot moving in a straight line for 2m.

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/AAhYKIU3b00" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                    </p>

                                    <h3>Simple Turning Motion</h3>
                                    <p class="mb-4">
                                        Next, I experimented with making the robot perform basic turns. This allowed me to verify that the robot is capable of turning.
                                        I separated the turning logic into different functions, as shown in this code snippet.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/twoMotorsTurnFunctions.png" width="300">

                                        <br>
                                        <br>

                                        I used the <code>delay</code> function to specify the turning angles (longer delays imply larger angles).

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab5/twoMotorsTurnsLoop.png" width="300">

                                        <br>
                                        <br>
                                        
                                        The video below shows the robot performing these turns.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/SMS24ynKHrY" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>
                                        
                                    </p>

                                    <h1>Frequency Generation</h1>
                                    <p class="mb-4">
                                        According to the <a href="https://www.arduino.cc/en/Reference/AnalogWrite&prev=search">Arduino website</a>, <code>analogWrite</code> 
                                        produces a PWM signal with a frequency of <code>490 Hz</code>. During my tests, I observed that rapid changes to the PWM signal values 
                                        are not precisely reflected by the motors. The motor driver's datasheet indicates that each motor driver's max PWM frequency is 
                                        <code>50 kHz</code>. This indicates that I could increase the PWM frequency up to 10x its current value. However, I don't believe the 
                                        motors will necessarily respond to such a drastic increase since the analog PWM signal is still just an average.
                                        
                                    </p>

                                    <h1>Speed Ramp Up/Down</h1>

                                    <p class="mb-4">
                                        The last part of the lab involving slowly increasing and decreasing the robot's speed, and using the attached sensors to calculate the 
                                        speed. I used Bluetooth to send commands to the robot as well as transmit sensor data back to my laptop. The two images below show the 
                                        Python ramp up and ramp down code, respectively. This wirelessly instructed the robot to move forward at the specified speed, and then 
                                        obtained the robot's velocity (<code>acceleration * time</code>) from the IMU.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/RampUp.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/RampDown.png" width="300">

                                        <br>
                                        <br>

                                        The following two snippets show the Arduino code. Based on the direction provided, I wrote the appropriate values to each PWM pin.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/MoveForward.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/moveForwardCase.png" width="300">

                                        <br>
                                        <br>

                                        The images below show the outputs of three unique trials. The last trial only includes the ramp up logic. I didn't want to move the robot too fast, 
                                        so the fastest speed I achieved was <code>0.5171 m/s</code>.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/RampUpDown1.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/RampUpDown2.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab5/LargestRampUp.png" width="300">

                                        <br>
                                        <br>

                                        The videos below show the three trials.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/9U-KYbGKd5w" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/8VQ8uTGCPYM" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Zc-pNL52WVI" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                    </p>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 6-->
        <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" aria-labelledby="portfolioModal6" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 6: Closed-Loop Control (PID)</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab6/PID.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to implement PID control. I improved upon the BLE protocol 
                                        I used in lab 2 to make debugging much easier. Incrementally, I fine-tuned my PID 
                                        control based on the system requirements and ultimately got it working for slower 
                                        speeds. I will continue to improve it over the next two labs.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Battery Packs (600mAh and 850mAh)</p>
                                    <p>2 dual motor drivers</p>
                                    <p>ToF sensor</p>
                                    <p>RC Car</p>
                                    
                                    <h1>BLE Protocol Improvement</h1>
                                    <p class="mb-4">

                                        I started by improving the BLE protocol that I had used in lab two. This made debugging and performing simple tasks, such as 
                                        adjusting the location of the robot, much easier. I had to generate additional uuids and create more characteristics, since I 
                                        was going to be trasmitting more data using bluetooth.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/BLE_additional_uuids.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/BLE_additional_characteristics.png" width="500">

                                        <br>
                                        <br>

                                        Then, I updated the robot control class provided. I implemented functions that 
                                        would automatically store sensor values using a notification handler, update the fields that stored these values, and explicitly obtain 
                                        sensor values.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/RC_Class_1.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/RC_Class_2.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/RC_Class_3.png" width="500">

                                        <br>
                                        <br>

                                        For all of these functions, I had corresponding Arduino code that performed the task. The two images below show example functions called 
                                        to obtain sensor values.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/getTOFFunction.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/getIMUCaseFunction.png" width="300">

                                        <br>
                                        <br>

                                        Additionally, I created functions to control the robot. I created a function to move the robot forward. I wanted to be able to use 
                                        this function for multiple tasks, so I added in arguments for speed, direction, and whether the robot should perform PID 
                                        while moving.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/RC_move_forward.png" width="500">

                                        <br>
                                        <br>

                                        On the Arduino side, I set variables accordingly, when this command was run, as depicted in the first image below. Then, this 
                                        would call another function which set the values of the PWM pins based on the direction, as shown in the second image.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/moveForwardCase.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/moveForwardCaseFunction.png" width="500">

                                        <br>
                                        <br>

                                        I also added in a function to stop the robot. I frequently used this command to avoid crashing into walls.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/RC_stop_robot.png" width="300">

                                        <br>
                                        <br>

                                        Similar to the move forward situation, I implemented essentially the same logic on the Arduino side. The only difference 
                                        was the function called and the values written to the PWM pins.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/stopRobotCase.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/stopRobotFastFunction.png" width="300">

                                        <br>
                                        <br>

                                        I also created a function for updating the PID constants. This allowed me to easily experiment with changing the values of the 
                                        constants as well as the setpoint.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/RC_update_PID.png" width="500">

                                        <br>
                                        <br>

                                    </p>

                                    <h1>Task Overview</h1>
                                    <p class="mb-4">

                                        I chose to work on Task A: Don't Hit the Wall. The goal was to drive the robot fast in the direction of a wall and then stop 
                                        when the robot is <code>300 mm</code> from the wall. I relied on my front ToF sensor to determine the distance to the wall.
                                        For my PID controller, I needed to define the setpoint and error. Since the objective was to have the robot stop at <code>300 mm</code>, 
                                        I chose a setpoint of <code>300</code>. I defined the error as <code>Front ToF Sensor Reading - Setpoint</code>.

                                        <br>
                                        <br>

                                        When I implemented any PID controller, my general workflow included calculating the respective value, setting the motor speed to the value, 
                                        writing that value to the BLE characteristic, and lastly writing that value to the PWM pins. The following three images show these steps.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_P.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_setMotor.png" width="300">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_end.png" width="300">

                                        <br>
                                        <br>

                                    </p>

                                    <h1>Initial Proportional Controller</h1>
                                    <p class="mb-4">

                                        I started simple by implementing a P controller. Thus, I set the motor value to <code>k_p * error</code>, where <code>k_p</code> was 
                                        the proportional constant.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_P.png" width="300">

                                        <br>
                                        <br>
                                        
                                        From the previous lab, the minimum PWM signal was 30. Additionally, I capped the signal at 150 since I didn't want the 
                                        robot to go too fast while I was tuning the controller. Since the ultimate stunt will require 2 meters, the maximum error is 1700 (<code>mm</code>). 
                                        Since the smallest PWM signal is 30, the smallest value of <code>k_p = 30 / 1700 = 0.018</code>. Theoretically, the optimal <code>k_p</code> could be 
                                        fairly large since the error might be small and the maximum PWM signal that I allowed was <code>150</code>. After performing some basic tests with 
                                        <code>k_p</code> values between <code>0.05</code> and <code>0.8</code>, I realized that this sped the robot up very quickly and it was not able to 
                                        adequately recover and would end up hitting the wall. The plot and video below show this behavior.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Bad_Trial.png" width="300">

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/dxkfnVeUSYE" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        At low speeds, the simple P controller worked fine. I used <code>k_p = 0.05</code> and a starting motor value of <code>50</code>.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial4.png" width="300">

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/vOnz3Xa3Orw" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        At the higher speeds, if the robot didn't crash into the wall, it's momentum typically carried it closer to the wall. The plot and 
                                        video below shows an example of this.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial5.png" width="300">

                                        <br>
                                        <br>
                                        
                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/JblZXjodV7Y" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                    </p>

                                    <h1>Proportional-Integral Controller</h1>
                                    <p class="mb-4">

                                        Next, I added in an integral term to see how much it would improve the controller. Overall, it worked rather poorly since 
                                        it mainly just compounded the previous problem.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_I.png" width="300">

                                        <br>
                                        <br>

                                        This term accumulates the error for each time step. As a result, as the robot was far away from the setpoint, the 
                                        error was large, which made the cumulative error large, which significantly increased the motor speeds. This just made it more 
                                        likely for the robot to overshoot the setpoint. I experimented with using small values for <code>k_i = (0.0001-0.1)</code>, but they 
                                        still resulted in the robot overshooting the setpoint.

                                    </p>

                                    <h1>Proportional-Derivative Controller</h1>
                                    <p class="mb-4">

                                        I implemented a PD controller to help prevent the robot from hitting the wall. As the name suggests, the derivative term accounts for the rate 
                                        of change of the error. Specifically, I stored the previous error and compared that to the current error. If the error was decreasing, which was 
                                        indicated by <code>current error - previous error < 0</code>, then this reduced the speed of the motors, since it meant that we were getting closer 
                                        to the setpoint. On the other hand, if the error was increasing, then the speed of the motors increased, with the goal of getting closer to the 
                                        setpoint.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_D.png" width="300">

                                        <br>
                                        <br>

                                        <br>

                                        While observing my initial P and PI controllers, I noticed that the robot was frequently hitting into the wall. This was especially noticeable when 
                                        I used a larger starting speed or started farther away from the wall, which resulted in the robot reaching a larger maximum speed. The fundamental problem 
                                        was that the robot didn't stop fast enough once it reached the setpoint. 
                                        
                                        As a result, I thought that I would need a fairly large <code>p_d</code> constant, so that I could rapidly account for when the robot approached the 
                                        setpoint and preemptively slow down the motors before the robot reached the setpoint.

                                        <br>
                                        
                                        I performed three trials, and two worked somewhat well. For each trial, I set the starting motor speed to <code>75</code>. For the first trial (depicted below), 
                                        I set <code>p_k = 0.30</code> and <code>p_d = 0.80</code>. This resulted in the robot hitting into the wall. As a result, I reduced both <code>p_k</code> and 
                                        <code>p_d</code> with the hopes of making the robot slow down more before the setpoint.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial30.png" width="300">

                                        <br>
                                        <br>
                                        
                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Tg3nBBDJBhY" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        For the second trial (depicted below), I set <code>p_k = 0.20</code> and <code>p_d = 0.70</code>. This worked better, but once the 
                                        robot passed the setpoint, it wasn't able to move back. Specifically, the PWM signals were too small for it to move backwards. I 
                                        increased the constants to try to combat this.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial31.png" width="300">

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/nOVcx7Hr980" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        For the third trial (depicted below), I set <code>p_k = 0.25</code> and <code>p_d = 0.75</code>. This trial also worked, but similar 
                                        to the previous trial, the robot didn't make it back to the setpoint. It did reach a larger top speed with this trial, since I increased 
                                        the <code>p_k</code> constant.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial32.png" width="300">

                                        <br>
                                        <br>
                                        
                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/DZdnseyjvfs" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>


                                    </p>

                                    <h1>Proportional-Integral-Derivative Controller</h1>
                                    <p class="mb-4">

                                        Lastly, I combined everything to improve the controller. From my previous analysis, I knew that I wanted the integral term 
                                        to be small, so I experimented with extremely small values (<code><0.0001</code>). I used similar constants for 
                                        the proportional and derivative terms, but after experimentation settled on <code>k_p = 0.35, k_i = 0.00001, and 
                                        k_d = 0.75</code>. I have included three successful runs below. For each trial, the starting motor value was <code>75</code> 
                                        and the setpoint was <code>300</code>.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial100.png" width="300">

                                        <br>
                                        <br>
                                        
                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/0slL76s-1YI" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial101.png" width="300">

                                        <br>
                                        <br>
                                        
                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/CNa0jLaAIx0" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/Trial102.png" width="300">

                                        <br>
                                        <br>
                                        
                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/QkLt0UKnZQA" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        Overall, I was able to achieve a maximum speed of <code>1.44 m/s</code>. I hope to improve on this during the next 
                                        two labs as I develop a better controller.

                                    </p>

                                    <h1>Other Considerations</h1>
                                    <p class="mb-4">

                                        <h3>Deadband and Max PWM Signal Thresholding</h3>
                                    
                                        I had to account for deadband. From the previous lab, I found that PWM signals below 30 barely run on the floor (carpet where I 
                                        did most of my testing). On the other hand, I had to limit the max PWM signal that I sent to the motors since I didn't want the 
                                        robot to crash during testing.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_deadband_threshold.png" width="300">

                                        <br>
                                        <br>


                                        <h3>Sampling Frequency</h3>

                                        I didn't have a problem with the default sampling frequency so I didn't change it. I removed unnecessary <code>Serial.println()</code> 
                                        statements from the code to avoid reducing the sampling frequency. In the next labs, I may increase the sampling frequency as I attempt 
                                        to make the robot move faster.
                                        
                                        <br>
                                        <br>

                                        <h3>Backwards Movement</h3>

                                        In my initial implementations, I solely made the robot go forward and then stop when it reached the setpoint. As I discussed previously, 
                                        this frequently resulted in the robot crashing into the wall. I had implemented this feature by setting the motor value to <code>30</code> 
                                        if the new value was less than <code>30</code>. This forced negative values to 30, which still moved the robot forward. I updated logic by 
                                        analyzing the sign of the error. If <code>error > 0</code>, then the robot hadn't reached the setpoint yet, so I continued moving the robot 
                                        forward. On the other hand, if <code>error < 0</code>, then the robot had reached and passed the setpoint, so I flipped the diirection variable 
                                        and made the robot move backward.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PID_error_direction.png" width="500">

                                        <br>
                                        <br>

                                        <h3>"Hacks"</h3>

                                        The main "hack" I used was stopping the robot when it was <code>50 mm</code> away from the setpoint when moving forward and <code>10 mm</code> away 
                                        when moving backwards. I did this to "help" the PID controller. I was more conservative when moving backwards since the typical backwards speeds 
                                        were smaller, so the robot had less momentum while moving backwards.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab6/PIDStopClose.png" width="500">

                                        <br>
                                        <br>

                                    </p>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 7-->
        <div class="portfolio-modal modal fade" id="portfolioModal7" tabindex="-1" aria-labelledby="portfolioModal7" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 7: Kalman Filters</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab7/KF.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to implement a Kalman Filter. This allowed me to increase the speed of the robot as it 
                                        approached the wall since I no longer had to solely rely on the front ToF sensor, which samples fairly slowly.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Battery Packs (600mAh and 850mAh)</p>
                                    <p>ToF sensor</p>
                                    <p>RC Car</p>

                                    <h1>Step Response</h1>
                                    <p class="mb-4">

                                        I first executed a step response by keeping the robot stationary from the wall, then driving it at a constant 
                                        PWM signal towards the wall until it reached steady state, and lastly stopping the robot. I had to choose the step-size. In 
                                        the previous PID lab, I computed the PWM value by using my PID controller. The PWM value was generally between 30 and 
                                        130, so I chose the midpoint, 80, to be my step-size. I issued the appropriate commands over bluetooth (start collecting 
                                        data values, move the robot with a PWM value of 80, stop the robot, stop collecting data values). I used the <code>PING</code> 
                                        command to toggle between collecting and not collecting data values.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Python_StepResponse.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Arduino_PingUpdate.png" width="500">

                                        <br>
                                        <br>

                                        The following graphs display the ToF sensor output, calculated velocities from this distance data, and motor PWM input.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Trial400_TOF.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Trial400_Velocity.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Trial400_PWM.png" width="500">

                                        <br>
                                        <br>

                                        I used these graphs to measure the steady state speed and <code>90%</code> rise time <code>(t_90)</code>. I used the velocity graph 
                                        to determine the steady state speed. The initial spike in velocity around 4 seconds was when the robot started 
                                        moving. It reached steady state a little bit after 6 seconds, at which the speed was approximately constant at 
                                        <code>2000 mm/s</code>. I calculated <code>90%</code> of this speed and determined how long it took for the robot 
                                        to reach this speed, starting from the time of the initial spike (when the robot started moving). I analyzed the graph 
                                        and determined this time to be <code>2.5339</code> seconds. Based on the examples from lecture, my A matrix was 
                                        <code>[ [ 0, 1], [0, -d/m] ]</code>, where <code>d = 1 / (steady state speed)</code> and 
                                        <code>m = (-d * t_90) / ln(1 - 0.9)</code>. This resulted in <code>[ [0,1], [0, -0.9087] ]</code> for the A matrix. My 
                                        B matrix was <code>[ [0], [1/m] ]</code>, which resulted in <code>[ [0], [1817.4489] ]</code>.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/AB_Matrices.png" width="500">
                                    
                                    </p>

                                    <h1>Kalman Filter: Setup</h1>
                                    <p class="mb-4">

                                        The first step in setting up the Kalman Filter was creating the process and sensor noise covariance matrices. I estimated 
                                        the sensor variance and approximate levels of noise. One covariance matrix was for the process noise, which represented 
                                        my trust in the modeled position and speed. For instance, the first element in this matrix corresponded to how far off 
                                        the ToF sensor measurement is anticipated to be per second. I estimated this value to be 100 mm. The second element 
                                        corrresponded to how far off the speed will be and I estimated this value to be 100 mm/s. I chose these values 
                                        to be larger than what I expected, so that I could simply reduce these values slowly as I made the robot move faster. 
                                        The second covariance matrix was for the measurement noise, and it represented how much I trust the sensor data. 
                                        Specifically, larger values indicate that there is more sensor error. For this matrix, I chose a value of 20 since I mostly 
                                        trusted the sensor values (the main problem was the slow sampling rate). I modified all of these values after implementing 
                                        the Kalman Filter on the robot.

                                        <br>
                                        <br>

                                        Then, I created the C matrix. My state space had one state and two dimensions. The one state was measuring the distance 
                                        to the wall. The two dimensions were distance to the wall and PWM motor value. As a result, my C matrix was <code>
                                        [ [1, 0] ] </code>, since my distance to the wall was greater than <code>0</code> (at least initially) and the 
                                        starting PWM value was 0.
                                    
                                    </p>

                                    <h1>Kalman Filter: Sanity Check</h1>
                                    <p class="mb-4">

                                        Before implementing the Kalman Filter on the Artemis, I tested it on data I recorded from the previous lab. I initialized 
                                        the state vector to <code>[ [Starting ToF Value, 0] ]</code> since the robot started that far from the wall and was 
                                        stationary. Next, I had to discretize my A and B matrices since I was running the Kalman Filter on pre-recorded data.

                                        I used the following two equations: <code>Ad = np.eye(2) + Delta_T * A</code> and <code>Bd = Delta_t * B</code>, which 
                                        were provided.

                                        <br>
                                        <br>

                                        I adapted the provided code to perform the Kalman Filter on data (ToF reading, motor PWM value) at one point in time.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Python_KF_Part2.png" width="500">
                                        
                                        <br>
                                        <br>

                                        I had to loop through all of the previous data, and call this function for every datapoint. Since I used the step response to 
                                        general some of the KF parameters, I had to scale down the PWM motor value so that it was in the range <code>[0, 1]</code>. 
                                        The plots below depict the output for my initial covariance matrices.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Python_KF_Part1.png" width="500">
                                        
                                        <br>
                                        <br>

                                        <img>

                                        <img>

                                        I experimented with these matrices to ensure the KF changed as I expected it to. First, I used the covariance matrix values I stated 
                                        above, which are also displayed below, to assess the performance of the Kalman Filter. In the graph below, the blue line 
                                        represents the ToF sensor outputs and the orange line represents the KF output. The KF matched the sensor outputs fairly closely.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Initial_Covariance_Matrices.png" width="500">
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Python_KF_Initial.png" width="500">

                                        <br>
                                        <br>

                                        I repeated this process but used a larger value for the process noise covariance matrix, which placed less trust in the 
                                        model and more trust in the sensor values, and as a result the KF followed the sensor values much more closely.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Covariance_Matrices_Sensor.png" width="500">
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Python_KF_Sensor.png" width="500">

                                        <br>
                                        <br>

                                        I repeated this process again but used larger values for the measurement noise covariance matrix, which implied that the 
                                        sensor measurements have more error and placed less trust in the sensor values, and as a result the KF followed the sensor 
                                        values less closely.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Covariance_Matrices_Model.png" width="500">
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab7/Python_KF_Model.png" width="500">

                                        <br>
                                        <br>
                                    
                                    </p>

                                    <h1>Kalman Filter: Artemis Nano Implementation</h1>
                                    <p class="mb-4">
                                    
                                        Now that I had finished testing my KF using old data, I proceeded to implement it on the Artemis. It was the same as my 
                                        Python implementation, just using a different language. I used the 
                                        <code>BasicLinearAlgebra</code> library to implement the KF on my robot. The following code snippet shows the 
                                        parameters that I initialized prior to the actual run.

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab7/Arduino_KF_Constants.png" width="500">

                                        <br>
                                        <br>

                                        The following snippet shows the KF function that ran at every time step. When there was a new sensor value, I incorporated that value 
                                        into the KF and performed the update step; otherwise, I didn't perform the update step and simply used the KF output in the PID controller.

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab7/Arduino_KF_Func.png" width="500">

                                        <br>
                                        <br>

                                        I modified my PID logic to incorporate the output of this function. The main difference was that I used the function's output, 
                                        instead of the front ToF sensor reading, to determine the error.

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab7/Arduino_KF_PIDChanges.png" width="500">

                                        <br>
                                        <br>

                                        The following videos and images show the outputs of three runs. For each run, I kept the PID coefficients the same 
                                        (<code>P = 0.05, I = 0, D = 0.75</code>), and only 
                                        varied the process noise covariance matrix value. The values I used were <code>1000, 1500, and 1000</code>, respectively. 
                                        I varied this parameter to assess the impact of following the front 
                                        ToF's sensor values more closely. The blue line depicts the KF output and the red dots are the front ToF sensor outputs. 
                                        The KF did help since the ToF sensor is so slow, but I still need to fine tune the matrices based on the lab floor since I 
                                        did most of my tests on a carpet. I was able to reduce the oscillations about the setpoint, which were very prevalent in 
                                        previous labs.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/74YuUwqq-FA" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; 
                                        encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab7/KF_Take1.png" width="500">

                                        <br>
                                        <br>

                                        <hr>

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/F5RwUj94G8M" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; 
                                        encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab7/KF_Take2.png" width="500">

                                        <br>
                                        <br>

                                        <hr>
                                        
                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Se29MMgj8u8" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; 
                                        encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                                        
                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab7/KF_Take3.png" width="500">                                        

                                    </p>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 8-->
        <div class="portfolio-modal modal fade" id="portfolioModal8" tabindex="-1" aria-labelledby="portfolioModal8" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 8: Stunts</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab8/flip.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to combine the PID control from lab 6 with the Kalman Filter implementation from 
                                        lab 7 to perform fast stunts. I was able to perform the controlled stunt (Don't Hit the Wall) as well as 
                                        some open loop repeatable stunts. I had to make several adjustments to account for the performance of my 
                                        ToF sensors.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Battery Packs (600mAh and 850mAh)</p>
                                    <p>ToF sensor</p>
                                    <p>RC Car</p>

                                    <h1>Controlled Stunt: Don't Hit the Wall</h1>
                                    <p>
                                        The goal of this stunt was to drive the robot very fast towards the wall, perform a flip when the robot 
                                        was approximately <code>0.5 m</code> from the wall, and then drive the robot very fast past its initial 
                                        position.

                                        First, I updated my Kalman Filter implementation. Initially, I always performed the prediction and update 
                                        steps, as shown below.

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab8/KF_Function.png" width="500">

                                        <br>
                                        <br>

                                        I updated this logic to only perform both steps when the robot received a new sensor reading from the front 
                                        ToF sensor. I only ran the prediction step based on the motor PWM signal and KF model when I didn't have a new 
                                        sensor reading. The code snippets below reflect these changes. I used the default value of <code>-1000</code> 
                                        for the front ToF sensor reading, and then updated that value if there was a new value.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab8/KF_DetectNewReading.png" width="400">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab8/KF_UpdateLogic.png" width="500">

                                        <br>
                                        <br>

                                        I varied my PID and Kalman Filter parameters to adjust for the higher robot speed. However, I faced several problems 
                                        with my front ToF sensor. I rarely got a consistent reading, even in cases when the robot wasn't moving. I experimented 
                                        with varying the distance mode and integration time, but neither improved the sensor reading reliability. I verified that 
                                        this problem persisted across multiple surfaces. Regardless of the parameters I set, the sensor rarely detected distances 
                                        above <code>700 mm</code>, which was a major problem since the starting distance was about <code>2000 mm</code>.

                                        <br>
                                        <br>

                                        After many attempts, I got a somewhat acceptable attempt. However, the robot angled after performing the flip. Part 
                                        of the reason for this was because of my unreliable front ToF sensor.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/qZavU9h8heo"
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <br>
                                        <br>

                                        The image below shows the front ToF sensor readings for this run.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab8/AngledData.png" width="500">

                                        <br>
                                        <br>
                                        
                                        Since this wasn't perfect, I also did "bang-bang" control instead of relying on the front ToF sensor. I started 
                                        by moving the robot at full speed towards the wall. When it reached the sticky matt, I sent the command over 
                                        bluetooth to initiate the flip. This command consisted of moving all four wheels in the opposite direction at 
                                        max speed for a short period of time and then stopping. Lastly, I made the robot move forward (in this 
                                        opposite direction) at full speed. The image below shows these commands.
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab8/Stunt_bang_bang.png" width="500">

                                        <br>
                                        <br>

                                        <br>
                                        <br>

                                        I adjusted the PWM input values, the starting angle, and the starting distance. I also cleaned the wheels 
                                        of the robot. Ultimately, I was able to get a successful run that worked fairly well.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/ShEf8YThEX4" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <br>
                                        <br>

                                        The plots below show the ToF readings (red dots) and KF values (blue line) in the first plot, 
                                        and motor PWM values in the second plot for the stunt. I stopped measuring the ToF readings after 
                                        the robot got close to the wall, which is why the ToF readings don't increase near the again back 
                                        up to <code>2000 mm</code>. Even though I ended up using "bang-bang" control, my Arduino code still 
                                        performed PID whenever it received a new ToF value. After the robot got close to the wall and performed 
                                        the flip, I didn't want it to perform PID anymore and just return back to the starting line as fast 
                                        as possible.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab8/Stunt_Bad_Plot.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab8/Stunt_MotorInput.png" width="500">

                                    </p>

                                    <h1>Open Loop, Repeatable Stunts</h1>
                                    <p>

                                        <h3>Spin!</h3>

                                        The next stunt involved making the robot spin in place. I picked this stunt in preparation 
                                        for lab 9. Here are the control commands I sent to the robot.

                                        <br>
                                        <br>

                                        <ol style="list-style-position: inside;">
                                            <li>Turn CCW (for 2 seconds)</li>
                                            <li>Stop</li>
                                            <li>Turn CW (for 2 secconds)</li>
                                            <li>Stop</li>
                                        </ol>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/br5kldr66SM" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/IcvXw9zS0I8" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/F1vVRn_IXnM" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <br>
                                        <br>

                                        <h3>Draw a T!</h3>

                                        The next stunt involved making the robot draw the letter T. Here are the control commands 
                                        I sent to the robot.

                                        <br>
                                        <br>

                                        <ol style="list-style-position: inside;">
                                            <li>Move forward (for 0.5 seconds)</li>
                                            <li>Turn left (for 0.35 seconds)</li>
                                            <li>Move forward (for 0.5 seconds)</li>
                                            <li>Turn left (for 0.5 seconds)</li>
                                            <li>Move forward (for 0.75 seconds)</li>
                                            <li>Stop</li>
                                        </ol>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Cf6wWTpTwSI" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/ryqsDXlpRyQ" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/xNhk5IPgA90" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <br>
                                        <br>

                                        <h3>Double Flip</h3>

                                        <p>
                                            The last stunt I worked on was a double flip. The involved making the robot flip once (as I had 
                                            done before), then move in the opposite direction for some time and flip again. I didn't end up 
                                            completing this task for the well-being of my robot. While testing this stunt, the robot kept 
                                            hitting into walls, and I started to worry about its structural integrity, especially since I still 
                                            needed to use the ToF sensors and IMU in later labs. I may come back and redo this stunt at the end of 
                                            the semester.
                                        </p>

                                    </p>

                                    <h1>Bloopers</h1>
                                    <p>

                                        <h3>Robot vs. Individual</h3>

                                        Individuals can easily outrun the robot moving at max speed.

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/Zltu6tu9bfk" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>

                                        <br>
                                        <br>

                                        <h3>Robot vs. Individual + Tricycle</h3>

                                        Individuals can not easily outrun the robot when also steering a tricycle.

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/98JlZjO2GZU" 
                                        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; 
                                        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
                                        </iframe>
                                        
                                    </p>


                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 9-->
        <div class="portfolio-modal modal fade" id="portfolioModal9" tabindex="-1" aria-labelledby="portfolioModal9" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 9: Mapping</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab9/lineBasedMap.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to generate a map of a rectangular region of the lab. I placed 
                                        my robot in five locations within the region and used the robot's front ToF sensor to obtain 
                                        distance measurements at several different orientations. I combined all of these readings to 
                                        create the map. Lastly, I converted the distance data points to a line-based map which I compared 
                                        with the actual reegion to determine the accuracy of my approach and measurements. I will use 
                                        this line-based map in the future localization and navigation labs.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Battery Packs (600mAh and 850mAh)</p>
                                    <p>ToF sensor</p>
                                    <p>IMU</p>
                                    <p>RC Car</p>

                                    <h1>PID Control</h1>
                                    <p class="mb-4">

                                        When obtaining the distance measurements from the ToF sensor, I had to rotate the robot on its own axis. This 
                                        allowed me to calculate multiple data points at each location within the rectangular region, and thus reduce the total 
                                        number of locations. Ideally, the robot would rotate by a fixed amount for each turn, since this would result in the 
                                        best map after using transformation matrices to combine all readings.  
                                        
                                        <br>
                                        
                                        I used PID to rotate the robot for a fixed turn amount. I utilized a simple P controller where the setpoint was the 
                                        angle that the robot had to turn through. I used <code>20 degrees</code> as my setpoint, since that allowed me to obtain 
                                        <code>18</code> measurements per full rotation. As a result, I defined the error as the difference between the elapsed turned 
                                        angle and the setpoint. I determined the elapsed turn angle by comparing the current integrated gyroscope value with the previous 
                                        integrated gyroscope value. When the elapsed turn angle was within <code>2</code> degrees, I made the robot stop moving. To 
                                        limit sudden starts and stops, I made the robot wait a specified interval of time before it started turning again. I included 
                                        the relevant code snippet below.
                                        
                                        <script src="https://gist.github.com/roninsharma25/5f7912e5bd963b3b3c72c4b4f639eb6f.js"></script>

                                        After each <code>20</code> degree turn, I wrote the front ToF sensor's distance measurement and integrated gyroscope value to their 
                                        respective float characteristics. 

                                        <br>
                                        <br>

                                        The video below shows the robot successfully turning fairly well on axis.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/wXMcbodNhKw" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        The plot below shows the output gyroscope values for <code>P = 0.25</code>.
                                        
                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/gyro_vals.png" width="500">

                                        <br>
                                        <br>

                                        The plot below shows the turn angle for each turn.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/gyro_val_diffs.png" width="500">

                                        <br>
                                        <br>

                                        Overall, the robot did not turn exactly <code>20</code> degrees every time, but it was fairly close <code>(+/- 5 degrees)</code>. 
                                        The video below shows the robot turning on the lab floor. Unfortunately, it did move while turning which will impact my final 
                                        map.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/9QNsqm4CDCI" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        On average, the robot's orientation changes by <code>17 degrees</code> during a single measurement. The maximum error would 
                                        occur if I registered the front ToF sensor's value at a <code>90 degree</code> orientation instead of at the expected 
                                        <code>~73 degrees</code>. I will discuss this later, but the error in the computed <code>x-position</code> would be 
                                        <code>2000 mm * 1 - cos(90-73) = 87 mm</code> (<code>2000 mm</code> since the robot will start centered). However, 
                                        this assumes that my ToF sensors operate fairly well, which is not the case. On average, my ToF sensors are off by <code>
                                        100 mm</code>, so the theoretical max error should be <code>187 mm</code>. My robot also doesn't turn on axis incredibly 
                                        reliably and moves by approximately <code>200 mm</code> per full rotation, increasing the max error to <code>387 mm</code>. 
                                        The average error should be smaller than this, but it probably won't be the case.

                                    </p>
                                    
                                    <h1>Read Out Distances</h1>
                                    <p class="mb-4">

                                        <img src="assets/img/Lab9/Lab.png" width="500">

                                        <br>
                                        <br>

                                        I placed my robot at each of the <code>5</code> marked locations in the lab and used my PID controller to 
                                        make it rotate in <code>20</code> degree increments for <code>45</code> seconds. I specified this amount of 
                                        time to ensure that the robot would complete more than one rotation, since it stopped momentarily after each 
                                        turn. I ended up only using the datapoints from the first rotation. I sent the start PID command, which 
                                        started the turning, over bluetooth.

                                        <script src="https://gist.github.com/roninsharma25/7b826eba5763c75982e23e8879910c01.js"></script>
                                    
                                    </p>

                                    <h1>Plot Readings</h1>
                                    <p class="mb-4">

                                        I plotted the integrated gyroscope values and ToF distance sensor values in a polar plot, as shown below.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/Polar_0_0.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/Polar_0_3.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/Polar_5_3.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/Polar_5_minus3.png" width="500">

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/Polar_minus3_minus2.png" width="500">

                                        <br>
                                        <br>

                                        I used the individual plots to verify that I obtained readings at roughly <code>20</code> 
                                        degree increments. I analyzed individual plots after each run to ensure that the angle 
                                        measurements line up with what I observed while watching the robot turn. 

                                    </p>

                                    <h1>Merge Data</h1>
                                    <p class="mb-4">

                                        Lastly, I combined the sensor data from all of the individual locations to construct the map. For each data 
                                        point, I had the sensor value <code>(r)</code> and the corresponding angle <code>(thetha)</code>. I had to 
                                        convert each of these datapoints to <code>x, y</code> coordinates. I used the formulas <code>x = r * cos(thetha)</code> 
                                        and <code>y = r * sin(thetha)</code>, based on transformation matrices. I also had to adjust for the different 
                                        locations. The lab had each location mapped as follows.

                                        <br>
                                        <br>

                                        <script src="https://gist.github.com/roninsharma25/9dd3aa3cad7511ad9aa82da75a5356bb.js"></script>

                                        <br>
                                        <br>

                                        These values represent tile coordinates. Each tile was <code>300 mm</code>, so I simply multiplied the tile coordinates 
                                        by <code>300</code>. I added these deltas to the previous values. Specifcally, <code>x_final = r * cos(thetha) + 
                                        tile_x * 300</code> and <code>y_final = r * sin(thetha) + tile_y * 300</code>. The last step in converting the measurements 
                                        to the inertial reference frame of the room was accounting for the ToF sensor's placement on the robot. The robot rotated 
                                        about its center, and the sensor was mounted <code>90 mm</code> from the center, so I subtracted 90 from each <code>x</code> 
                                        measurement. Finally, <code>x_final = r * cos(thetha) + tile_x * 300 - 90</code>.

                                        <br>
                                        <br>

                                        I iterated over every data point and performed this calculation to convert it to <code>x, y</code> coordinates, as depicted in the 
                                        snippet below.

                                        <script src="https://gist.github.com/roninsharma25/448fcbd925f109abb1f7b19b86149051.js"></script>

                                        Now that I had all the <code>x, y</code> coordinates, I plotted them, stratified by location. I added in the lines representing the outlines 
                                        for the boundary and obstacles. I obtained the positions for these lines from the lab 10 repository (pink). The cyan borders represent the 
                                        boundaries that I determined experimentally from my ToF data. I included the two boundary point lists below the graph. The first list (boundary) 
                                        consists of the points I added and the second list (world) consists of the points provided in the lab 10 setup.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab9/lineBasedMap.png" width="500">

                                        <br>
                                        <br>

                                        <script src="https://gist.github.com/roninsharma25/994588867981827e3d82ac21c10bdad5.js"></script>

                                        Overall, my sensor values weren't perfect. Part of this is because the robot didn't perfectly spin on axis. The plot shows the best run as 
                                        the previous runs were much worse. Another reason for the poor readings is the inconsistency of my front ToF sensor. As I mentioned in my 
                                        lab 8 wiki, sometimes it simply can't detect values greater than <code>600 mm</code>, regardless of the distance mode, and sometimes 
                                        it consistently detects values too large, regardless of the integration time. Generally, I was able to detect the box near the center of 
                                        the space, and was somewhat able to detect the box near the boundary. The gyroscope values would also drift over time so that could have 
                                        contributed to errors in the computed angles.
                                    
                                    </p>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 10-->
        <div class="portfolio-modal modal fade" id="portfolioModal10" tabindex="-1" aria-labelledby="portfolioModal10" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 10: Simulator</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab10/Simulator.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The purpose of this lab was to setup and get familiar with the robot simulation environment. 
                                        I was able to perform all setup steps and run the simulator effectively to control the virtual 
                                        robot to perform simple objectives along with obstacle avoidance.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Laptop</p>

                                    <h1>Setup</h1>
                                    <p class="mb-4">

                                        <ol style="list-style-position: inside;">
                                            <li>Upgrade <code>Python</code> version to <code>3.10</code></li>
                                            <li>Upgrade <code>pip</code> version to <code>21.0</code></li>
                                            <li>Delete and recreate virtual environment using the updated
                                                 <code>Python</code> version</li>
                                            <li>Install dependencies: <code>numpy pygame pyqt5 pyqtgraph 
                                                pyyaml ipywidgets colorama</code></li>
                                            <li>Install <code>Box2D</code></li>
                                        </ol>
                                        
                                    </p>
                                    
                                    <h1>Simulation Environment</h1>
                                    <p class="mb-4">

                                        <h3>Overview</h3>

                                        The simulation environment includes a simulator and plotter for controlling the virtual robot. The 
                                        virtual robot has a laser range finder, which functions very similarly to the ToF sensors on 
                                        my robot. There is a GUI that can be used to start, stop, and reset both the simulator and plotter. 
                                        This can also be done programmatically by using the following functions: <code>START_SIM(), START_PLOTTER(), 
                                        STOP_SIM(), STOP_PLOTTER(), RESET_SIM(), RESET_PLOTTER()</code>.
                                        
                                        <br>
                                        <br>

                                        <h3>Simulator</h3>

                                        The simulator records the ground truth of the robot, which is the actual position of the robot. It also 
                                        uses the sensors to estimate changes in position over time. Specifically, these changes are integrated over 
                                        time to predict the location of the robot. The simulator provides this odometry pose estimate.
                                        
                                        <br>
                                        <br>

                                        There are functions to set the linear and angular velocity of the virtual robot, get the odoometry and 
                                        ground truth of the virtual robot, get the distance sensor data of the virtual robot, and reset the position 
                                        and orientation of the virtual robot to its initial state.

                                        <br>
                                        <br>

                                        <h3>Plotter</h3>

                                        The plotter tool plots the ground truth and odometry poses.
                                        
                                        <br>
                                        <br>

                                        There are functions to plot points in the plotter in red, green, or blue, plot a map (sequence of points), 
                                        and reset the plotter.
                                    </p>

                                    <h1>Open Loop Control</h1>
                                    <p class="mb-4">

                                        The main open loop control task that I performed was making the virtual robot execute a "square" 
                                        loop. I issued the <code>velocity</code> command for <code>1</code> second intervals as the robot 
                                        either moved forward or turned. I used the <code>asyncio</code> module to wait for <code>1</code> 
                                        second in between forward commands. 

                                        <br>
                                        <br>

                                        <script src="https://gist.github.com/roninsharma25/59076ff4df869f8d1b40a9987c6da84e.js"></script>
                                        
                                        <br>
                                        <br>

                                        Simply issuing a velocity command will make the robot move 
                                        at that velocity forever, until another velocity command is sent that changes the velocity.
                                        
                                        <br>
                                        <br>

                                        The videos below show multiple iterations of the robot drawing squares. The simulator and 
                                        plotter are depicted side-by-side. On the plotter on the right, the green lines represent 
                                        the ground truth and the red lines represent the calculated positions (odometry poses).
                                        Overall, the robot did not always execute the same shape. This is because I utilized 
                                        angular speed and time duration to execute my turns. Specifically, 
                                        if I needed to turn <code>90</code> degrees, I utilized angular speed and time duration values that 
                                        multiplied to <code>90</code>. However, the function required the angular speed to have units of 
                                        <code>radians/sec</code>. Since the units involved radians, I had to involve <code>pi</code>, which 
                                        resulted in some level of approximation. As a result, the computed angle wasn't always exactly 
                                        <code>90</code> degrees. Since I had to compute the angle four times per square, the error 
                                        was compounded so each square was slightly further off. Additionally, I used the <code>asyncio</code> 
                                        module for the time duration. While this module is fairly accurate, it is not perfect, so the timing 
                                        was not always the expected amount, which further propagated the angle error.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/0Uam0ObLsTM" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        The image below shows the ground truths for a few runs. Overall, the error angle wasn't huge, but it 
                                        was definitely noticeable. There were a few runs where the error was extremely small so it wasn't 
                                        noticeable, but this wasn't always the case.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab10/Ground_Truth_Five_Squares.png" width="500">

                                    </p>

                                    <h1>Closed Loop Control</h1>
                                    <p class="mb-4">

                                        I used the following class to control the virtual robot.

                                        <br>
                                        <br>

                                        <script src="https://gist.github.com/roninsharma25/58ace9b0d1a962075520384ef5ecccce.js"></script>

                                        <br>
                                        <br>

                                        When the virtual robot reaches an obstacle, it should keep turning until it no longer faces an 
                                        obstacle. Initially, I set this angle to <code>90</code> degrees which essentially guaranteed 
                                        that the robot would no longer face an obstacle after turning. I modified this to be a random 
                                        angle to make the robot movement nondeterministic.

                                        <br>
                                        <br>

                                        I implemented the following class functions to perform obstacle avoidance.

                                        <br>
                                        <br>

                                        <script src="https://gist.github.com/roninsharma25/deb34f264a8073ee63a3905057cfd68c.js"></script>

                                        <br>
                                        <br>

                                        <script src="https://gist.github.com/roninsharma25/d8dccc0d667813996019ebe9ac90b97d.js"></script>

                                        <br>
                                        <br>

                                        My obstacle avoidance code works most of the time (<code>99%</code>). There are unique cases when the robot is moving 
                                        in a straight line near an edge, but it doesn't detect that edge. Based on my trials, these situations 
                                        are very infrequent. However, mostly happened at very high speeds. At low speeds, they rarely happened 
                                        since the robot was able to detect an obstacle in front of it. Overall, by issuing the <code>
                                        set_velocity</code> commands in very short intervals, I was able to make the obstacle avoidance logic 
                                        nearly flawless. This ensures that the robot moves at very high speeds while turning prior to hitting into 
                                        a wall. Additionally, prior to moving forward, I check if the robot will hit into a wall if it was to 
                                        move forward at a specified speed for a specified time (<code>checkSafeMovement()</code>). This 
                                        ensures that the robot will not collide into a wall in front of it, since it will turn instead. As I mentioned 
                                        before, this works for almost every case, and solely doesn't work for the corner cases where the sensor 
                                        doesn't detect the obstale jutting out. However, tt is still possible for this to happen in slow speed cases, 
                                        as shown in the video below.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/ViiZFcW0GwA" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        The video below shows the robot navigating faster, since I capped the speed at <code>25 m/s</code> instead 
                                        of at <code>15 m/s</code>.

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/hn_reGnkCjk" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        The maximum linear speed I achieved was <code>6,227.8242 m/s</code>. I achieved this by making the virtual 
                                        robot move at large speeds (and constantly increasing the speed) for very short periods of time. To achieve 
                                        this speed, I set the maximum speed constant in my class to <code>10,000 m/s</code>  and the time interval 
                                        between forward commands to <code>0.001 s</code>. Initially I experimented with the following time intervals: 
                                        <code>0.50 s, 0.10 s, 0.01 s</code>, and I slowly scaled them down.
                                        After this short period of time, I checked the distance sensor value and turned the robot if it was close 
                                        to an obstacle. This prevented it from hitting into the wall. On average, the robot should move 
                                        slower (around <code>5 m/s</code>). Moving at this slower speed would make the obstacle collision 
                                        logic easier since it would be easier to control the robot at this slower speed, thus making it 
                                        easier to adjust the robot's movement. 


                                        <br>
                                        <br>

                                        The closest I was able to get to the wall without colliding was <code>0.082981 m</code>. I determined this 
                                        value by continously moving the robot closer to the wall, for different amounts of time, and calculated the 
                                        distance to the wall at the end of each movement. I stored all the final distances in a list and obtained 
                                        the smallest one. In my robot control class, I use a slightly larger minimum distance just to give the virtual 
                                        robot some more breathing room, especially since it was moving at such high speeds.

                                    </p>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 11-->
        <div class="portfolio-modal modal fade" id="portfolioModal11" tabindex="-1" aria-labelledby="portfolioModal11" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 11: Grid Localization using Bayes Filter</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <img class="img-fluid rounded mb-5" src="assets/img/Lab11/Bayes_Filter.png" alt="..." />
                                    <!-- Portfolio Modal - Text-->
                                    <br>
                                    <br>
                                    <i>Collaborated with Chris Chan</i>
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The goal of this lab was to use the robot simulation environment to implement 
                                        grid localization using Bayes filter. I expanded on initial simulation work 
                                        from lab 10 and created the foundation for lab 12.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Laptop</p>
                                    
                                    <h1>Preliminary Work</h1>
                                    <p class="mb-4">

                                        I started by reviewing the steps needed to perform grid localization using the robot 
                                        within the lab space. The robot can be located anywhere in this space, but I simplified 
                                        the analysis by reducing the continuous state space to a discretized finite 3D grid space.
                                        The robot's position in this space can be broken down into grid cells, and each grid cell 
                                        can be represented by (x, y, thetha). I will use the Bayes filter to compute the probability 
                                        of the robot being located in each cell. The image below depicts the entire discretized 
                                        state space.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab11/Entire_State_Space.png" width="500">

                                        <br>
                                        <br>

                                        I implemented five functions, which were all combined to perform the final grid localization.
                                        
                                    </p>

                                    <h1>Compute Control</h1>
                                    <p class="mb-4">

                                        The first function I completed was compute control. This helper function took in the previous 
                                        pose and the current pose as input arguments, and returned three transformations to get from 
                                        the previous pose to the current pose. The image below depicts these transformations (two 
                                        rotations and a translation).

                                        <br>
                                        <br>
                                        
                                        <img src="assets/img/Lab11/Compute_Control_Transformation.png" width="500">

                                        <br>
                                        <br>

                                        The odometry model of the motion between two states can be constructed by the initial rotation, 
                                        then a translation, and lastly a final rotation. In the function, I first calculated the change in 
                                        x, y, and thetha between the two poses. Then I used geometry and trigonometry to calculate the three 
                                        transformations. Lastly, I had to normalize the two angular transformations to fall within the correct
                                        range (<code>-180 degrees</code> to <code>180 degrees</code>), and I used the provided 
                                        <code>normalize_angle</code> function to do so.

                                        <script src="https://gist.github.com/roninsharma25/e600f87ab383ad3fd1116b4258de6321.js"></script>

                                    </p>

                                    <h1>Odomotry Motion Model</h1>
                                    <p class="mb-4">

                                        The second function was odomotry motion model. This helper function took in the previous pose, current pose, 
                                        and control input. The control input was defined similarly to the transformations in compute control, with 
                                        two rotation parameters and one translation parameter. This function returned the probability of transitioning 
                                        from the previous pose to the current pose (previous state to current state), based on the control input. I used 
                                        the <code>compute_control</code> function to calculate the control input required to move from the previous 
                                        pose to the current pose. I then used the provided <code>gaussian</code> function to compare this control input 
                                        with the control input argument, and calculated the probability of all three transformations occurring.


                                        <script src="https://gist.github.com/roninsharma25/a71bfb69fc400b210ae0f854226f8f85.js"></script>

                                    </p>

                                    <h1>Prediction Step</h1>
                                    <p class="mb-4">

                                        This function generated new probabilities that the robot was located in each grid cell. It took two 
                                        inputs: the previous and current poses from the odometry motion model. I used the <code>compute_control</code> 
                                        function to generate the control input (transformations) that are required to get from the previous 
                                        pose to the current pose. Then, for all of the previous dimensions and current dimensions, I used the 
                                        <code>odom_motion_model</code> function to calculate the probability of transitioning from the 
                                        previous pose to the current pose with the control input that I generated using <code>compute_control</code>. 
                                        Then, I updated the prior belief for each grid cell with these new probabilities. Lastly, I normalized all 
                                        the probabilities to ensure they summed to one. 

                                        <script src="https://gist.github.com/roninsharma25/8be132d2e9aa629e19ab469aa8f38518.js"></script>

                                        I did not compute new probabilities for every grid cell. I checked if the previous belief's probability 
                                        was greater than <code>0.0001</code>, and didn't loop over all the current dimensions if this was not the case. 
                                        This is because the new probability would be very close to <code>0</code>, since the previous probability 
                                        was so small, so this function would be more efficient if I just skipped over those grid cells.

                                        <br>
                                        <br>
                                        
                                        I referenced the lecture slide in the appendix to implement the prediction step of the Bayes filter.
                                    </p>

                                    <h1>Sensor Model</h1>
                                    <p class="mb-4">

                                        This helper function took the true observations for the current pose as an input and returned the probabilities 
                                        of the likelihoods of each observation. At each location, the robot obtained <code>18</code> equidistant 
                                        observations, since it rotated <code>20 degrees</code> at each location. In the function, I looped over 
                                        the true observations and used the provided <code>gaussian</code> function to calculate the probability of 
                                        each observation based on the sensor values obtained from the robot and the provided sensor noise. I multiplied 
                                        all of these probabilities together to get the total probability of all observations.

                                        <script src="https://gist.github.com/roninsharma25/b16dd20beee185a0acbf780491749474.js"></script>

                                    </p>

                                    <h1>Update Step</h1>
                                    <p class="mb-4">

                                        This function updated the probabilities of each grid cell based on the predicted probabilities (from 
                                        <code>predict_step</code>) and the computed probability for the current pose. In the function, I looped over 
                                        all of the current poses (grid cells), computed the probability for that pose using the <code>sensor_model</code> 
                                        function, and then multiplied that probability with the predicted probability for that grid cell, which was 
                                        stored in an attribute in the <code>BaseLocalization</code> object (I updated this attribute in the 
                                        <code>predict_step</code> function). Lastly, I normalized these probabilities so that they summed to 1.

                                        <script src="https://gist.github.com/roninsharma25/c7f403c296311d2dfb5fd620f3c0cf07.js"></script>
                                        
                                        I referenced the lecture slide in the appendix to implement the update step of the Bayes filter.

                                    </p>

                                    <h1>Profit!</h1>
                                    <p class="mb-4">

                                        Overall, my Bayes filter worked fairly well. The video below depicts it running for the provided trajectory. 
                                        It seems slow, but given the number of calculations it's performing at each grid location, I believe that it is fine. 
                                        I tried to minimize the extra variables I defined as well as the operations I performed within nested loops to make 
                                        it as efficient as possible. 
                                        
                                        <br>
                                        <br>

                                        In the video below, the green line is the robot's ground truth, the red line is the calculated positions 
                                        (odometry poses), and the blue line is the Bayes filter predicted belief. The highlighted cells show 
                                        probabilities, with lighter cells denoting higher probabilities (white cells indicate probabilities close 
                                        to 1).

                                        <br>
                                        <br>

                                        <iframe width="560" height="315" src="https://www.youtube.com/embed/UVnJr4tzuOk" title="YouTube video player" 
                                        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                                        allowfullscreen></iframe>

                                        <br>
                                        <br>

                                        The image below shows the output information from the run above. It shows the most probable state 
                                        after each iteration of the Bayes filter. Additionally, it includes the probability of that state 
                                        and the ground truth grid cell. Each iteration also has information about both the prediction and 
                                        update steps. There was a slight startup overhead where the Bayes filter overcompensated for the 
                                        control inputs which made it overshoot the predicted grid cells. It also seemed to work poorly 
                                        when the predicted probability was extremely small (<code>< 1E-9</code>). I believe these very 
                                        small probabilities skewed the updated probabilities by also making them comparatively small, which 
                                        negatively impacted the algorithm.

                                        <script src="https://gist.github.com/roninsharma25/c6797c548de391de95fc219283ca523c.js"></script>

                                    </p>

                                    <h1>Appendix</h1>
                                    <p class="mb-4">
                                        <img src="assets/img/Lab11/Bayes_Filter_Algorithm.png" width="500">
                                    </p>


                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Portfolio Modal 12-->
        <div class="portfolio-modal modal fade" id="portfolioModal12" tabindex="-1" aria-labelledby="portfolioModal12" aria-hidden="true">
            <div class="modal-dialog modal-xl">
                <div class="modal-content">
                    <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                    <div class="modal-body text-center pb-5">
                        <div class="container">
                            <div class="row justify-content-center">
                                <div class="col-lg-8">
                                    <!-- Portfolio Modal - Title-->
                                    <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 12: Localization on the Real Robot</h2>
                                    <!-- Icon Divider-->
                                    <div class="divider-custom">
                                        <div class="divider-custom-line"></div>
                                        <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                        <div class="divider-custom-line"></div>
                                    </div>
                                    <!-- Portfolio Modal - Image-->
                                    <!-- <img class="img-fluid rounded mb-5" src="assets/img/Lab10/Simulator.png" alt="..." /> -->
                                    <!-- Portfolio Modal - Text-->
                                    <h1>Overview</h1>
                                    <p class="mb-4">
                                        The goal of this lab was to perform localization on the physical robot. I adapted the 
                                        provided Bayes filter implementation to solely perform the update step after receiving 
                                        data from my robot.
                                    </p>

                                    <h1>Materials</h1>
                                    <p>Artemis Nano</p>
                                    <p>USB C-to-C Cable</p>
                                    <p>Two 4m Time-of-Flight Distance Sensors</p>
                                    <p>9DOF Inertial Measurement Unit Sensor</p>
                                    <p>Battery Packs (600 mAh and 850 mAh)</p>
                                    <p>RC Car</p>

                                    <h1>Simulation Verification</h1>
                                    <p class="mb-4">
                                        In this lab, I was provided with a working and optimized Bayes Filter implementation. I ran 
                                        the simulator using this implementation to verify that it worked as expected. Here is the final 
                                        plot, which looked reasonable, so I felt confident that it was working correctly. The robot followed 
                                        the correct trajectory, and the predicted positions were relatively close.

                                        <br>
                                        <br>

                                        <img src="assets/img/Lab12/Lab12_Final_Plot.png" width="500">
                                    </p>

                                    <h1>Localization on the Robot</h1>
                                    
                                    <h3>Implementation</h3>
                                    <p class="mb-4">
                                        Next, I moved onto implementing it on the robot. At each position, the robot needed to turn in 
                                        <code>20</code> degree increments and record the front ToF sensor reading. In lab 9, I performed this 
                                        task, but the results weren't great. My robot moved too much while turning, which when combined with 
                                        my unreliable ToF sensor readings created lots of problems. As a result, I modified my rotating in-place 
                                        approach. Instead, I had the robot turn a full <code>360</code> degrees, and used the gyroscope to identify 
                                        when <code>20</code> degrees had elapsed. After each turn, I recorded the front ToF sensor reading and sent 
                                        it to my laptop via bluetooth. By using this approach, I was able to turn my robot slightly faster, which 
                                        prevented it from skidding as much and it didn't move translationally as much during the turning process. I 
                                        also sent the gyroscope values to confirm that the ToF values were after <code>20</code> degree increments.

                                        <br>
                                        <br>

                                        I added a new robot function (specified using bluetooth) which makes the robot start turning and stores the initial 
                                        values. In the main loop function, if the robot has started turning, I constantly called the <code>turnUpdates()</code> 
                                        function, which updated the gyroscope readings, checked if one turn iteration finished, sent the appropriate values 
                                        over bluetooth, and finally stopped turning if the robot had turned enough times (<code>360</code> degrees). Through 
                                        experimentation, I found that waiting until the gyroscope changed by <code>19</code> degrees resulted in angle deltas 
                                        that were closer to <code>20</code>.

                                        <script src="https://gist.github.com/roninsharma25/7ef9aa065335a5efb2485834d74f59e7.js"></script>

                                        <br>

                                        <script src="https://gist.github.com/roninsharma25/b38c246c44db25d1c73631c69a636e81.js"></script>
                                    </p>

                                    <p class="mb-4">
                                        Then, I updated the provided code to utilize my onboard implementation. In the <code>RealRobot</code> class, the 
                                        <code>perform_observation_loop</code> function had to return the sensor values at the <code>20</code> degree 
                                        increments. In this function, I invoked the <code>TURN 360</code> robot command, waited for the turn to finish, 
                                        which I determined the time delay by experimentation, and reshaped the TOF sensor value array accordingly.

                                        <script src="https://gist.github.com/roninsharma25/eb7b55274ef0999ccb16237033909191.js"></script>

                                        <br>

                                        In the update step of the Bayes filter, the provided code automatically called this function (internally from the 
                                        <code>Localization</code> object, and used the results to determine the robot position). As provided, I used a 
                                        uniform prior belief for every cell value in the state space.
                                    </p>
                                    
                                    <h3>Results</h3>
                                    <p class="mb-4">
                                        I performed localization at four locations marked in the lab:

                                        <br>
                                        <br>
                                        <code>(-3 ft, -2 ft, 0 deg)</code>
                                        <br>
                                        <code>(0 ft, 3 ft, 0 deg)</code>
                                        <br>
                                        <code>(5 ft, -3 ft, 0 deg)</code>
                                        <br>
                                        <code>(5 ft, 3 ft, 0 deg)</code>
                                        <br>
                                        <br>

                                        Overall, my results were bad. The robot was consistently believed to be located within one of the obstacles. 
                                        The images below depict the actual and predicted positions for each location, where the actual position is the 
                                        green dot and the predicted position is the light blue dot. The predicted belief and corresponding probability are 
                                        depicted below each image.

                                        <br>
                                        <br>
                                        
                                        <h6><code>(-3 ft, -2 ft, 0 deg)</code></h6>
                                        <img src="assets/img/Lab12/loc_minus3_minus2.png" width="500">

                                        <br>
                                        <br>
                                        Predicted location: <code>(2.9987 ft, 1.0007 ft, 90 deg)</code>
                                        <br>
                                        <br>
                                        <img src="assets/img/Lab12/loc_data_minus3_minus2.png" width="500">


                                        <br>
                                        <br>

                                        <hr>

                                        <br>
                                        <br>
                                        
                                        <h6><code>(0 ft, 3 ft, 0 deg)</code></h6>
                                        <img src="assets/img/Lab12/loc_0_3.png" width="500">

                                        <br>
                                        <br>
                                        Predicted location: <code>(2.9987 ft, 0 ft, 110 deg)</code>
                                        <br>
                                        <br>
                                        <img src="assets/img/Lab12/loc_data_0_3.png" width="500">
                                        
                                        <br>
                                        <br>

                                        <hr>

                                        <br>
                                        <br>

                                        <h6><code>(5 ft, -3 ft, 0 deg)</code></h6>
                                        <img src="assets/img/Lab12/loc_5_minus3.png" width="500">

                                        <br>
                                        <br>
                                        Predicted location: <code>(2.9987 ft, 1.0007 ft, 70 deg)</code>
                                        <br>
                                        <br>
                                        <img src="assets/img/Lab12/loc_data_5_minus3.png" width="500">

                                        <br>
                                        <br>

                                        <hr>

                                        <br>
                                        <br>

                                        <h6><code>(5 ft, 3 ft, 0 deg)</code></h6>
                                        <img src="assets/img/Lab12/loc_5_3.png" width="500">
                                        <br>
                                        <br>
                                        Predicted location: <code>(2.9987 ft, 1.0007 ft, 90 deg)</code>
                                        <br>
                                        <br>
                                        <img src="assets/img/Lab12/loc_data_5_3.png" width="500">
                                    </p>

                                    <h3>Analysis</h3>
                                    <p class="mb-4">
                                        One possible reason for the poor results is duplicate values. On the robot side, I use the <code>checkForDataReady()</code> function 
                                        before reading a new ToF sensor value, otherwise I use the old value. Despite varying and reducing the integration time, 
                                        there were some scenarios where the robot recorded the same ToF sensor reading for adjacent turn angles. The plots below 
                                        show some examples.
                                        
                                        <br>
                                        <br>

                                        <h6><code>(-3 ft, -2 ft, 0 deg)</code></h6>
                                        <img src="assets/img/Lab12/sensorReadings_minus3_minus2.png" width="500">

                                        <br>
                                        <br>

                                        <hr>

                                        <br>
                                        <br>

                                        <h6><code>(0 ft, 3 ft, 0 deg)</code></h6>
                                        <img src="assets/img/Lab12/sensorReadings_0_3.png" width="500">

                                        <br>
                                        <br>

                                        Also, regardless of the distance mode I set, my ToF sensors seem to get capped around <code>700-800</code> mm. Sometimes, they will 
                                        be able to detect larger distances, but they do so very rarely and the values are very inconsistent. I have also been obtaining 
                                        fairly inconsistent values at smaller distances as well.
                                        
                                        <br>
                                        <br>

                                        Despite performing several trials, none of the localization results worked well. I also tried to use my other ToF sensor, but it 
                                        didn't work much better. This was quite disappointing. I was surprised that the predicted position was so similar across the four 
                                        marked positions. They overlapped for several trials, but had different angles so they weren't identical. I thought this could have 
                                        been a problem with my implementation, but the probabilities were also different (as shown in the images above) so it wasn't somehow 
                                        using the same data for all trials. I will have to improve this for the final lab.
                                    </p>

                                    <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                        <i class="fas fa-times fa-fw"></i>
                                        Close Window
                                    </button>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

       <!-- Portfolio Modal 13-->
       <div class="portfolio-modal modal fade" id="portfolioModal13" tabindex="-1" aria-labelledby="portfolioModal13" aria-hidden="true">
        <div class="modal-dialog modal-xl">
            <div class="modal-content">
                <div class="modal-header border-0"><button class="btn-close" type="button" data-bs-dismiss="modal" aria-label="Close"></button></div>
                <div class="modal-body text-center pb-5">
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-8">
                                <!-- Portfolio Modal - Title-->
                                <h2 class="portfolio-modal-title text-secondary text-uppercase mb-0">Lab 13</h2>
                                <!-- Icon Divider-->
                                <div class="divider-custom">
                                    <div class="divider-custom-line"></div>
                                    <div class="divider-custom-icon"><i class="fas fa-star"></i></div>
                                    <div class="divider-custom-line"></div>
                                </div>
                                <!-- Portfolio Modal - Image-->
                                <img class="img-fluid rounded mb-5" src="assets/img/Lab10/Simulator.png" alt="..." />
                                <!-- Portfolio Modal - Text-->
                                <h1>Overview</h1>
                                <p class="mb-4">
                                    
                                </p>

                                <h1>Materials</h1>

                                <h1>Setup</h1>
                                <p class="mb-4">

                                </p>

                                <button class="btn btn-primary" href="index.html" data-bs-dismiss="modal">
                                    <i class="fas fa-times fa-fw"></i>
                                    Close Window
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
        <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
        <!-- * *                               SB Forms JS                               * *-->
        <!-- * * Activate your form at https://startbootstrap.com/solution/contact-forms * *-->effecteiisfbbi-zxcvcxx
        <!-- * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-->
        <script src="https://cdn.startbootstrap.com/sb-forms-latest.js"></script>
    </body>
</html>
